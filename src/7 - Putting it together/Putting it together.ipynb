{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'7 - Putting it together')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from data_loading import *\n",
    "from model import *\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct  5 16:07:22 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.51.01              Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   33C    P0             51W /  450W |    3400MiB /  24564MiB |     38%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        29      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        41      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3839"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'vg_large'\n",
    "midi_path = Path(f'../data/midi/{dataset_name}')\n",
    "score_path = Path(f'../data/numpy/{dataset_name}/all')\n",
    "midi_file_paths = list(midi_path.rglob('*.mid')) #[f for f in os.listdir(midi_path) if os.path.isfile(os.path.join(midi_path, f))]\n",
    "\n",
    "# Ensure files are shuffled directly after assignment.\n",
    "# If they are shuffled in a different cell, and that cell is run multiple times, the order will change as we are shuffling the already-shuffled list.\n",
    "random.seed(42)\n",
    "random.shuffle(midi_file_paths)\n",
    "\n",
    "len(midi_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file names: 3071, Valid file names: 384, Test file names: 384\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * len(midi_file_paths))\n",
    "n2 = int(0.9 * len(midi_file_paths))\n",
    "train_filepaths = midi_file_paths[:n1]\n",
    "valid_filepaths = midi_file_paths[n1:n2]\n",
    "test_filepaths = midi_file_paths[n2:]\n",
    "\n",
    "print(f'Train file names: {len(train_filepaths)}, Valid file names: {len(valid_filepaths)}, Test file names: {len(test_filepaths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 389\n",
    "vocab_name = f'{dataset_name}-actions_{max_vocab_size}'\n",
    "vocab_state_dict_path = Path(f'../data/vocab/{vocab_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MidiDataset says \"Look for the given filenames at the given score path. Load if they exist, if not create them'.\n",
    "\n",
    "We can use this to encode with the trained vocab if we pass it in as a param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n",
      "Loaded vocab with actions:\n",
      "[]\n",
      "Trained vocab size: 389\n"
     ]
    }
   ],
   "source": [
    "sample_length = 256\n",
    "max_file_length = 32\n",
    "\n",
    "if not vocab_state_dict_path.exists():\n",
    "    \n",
    "    # Load (and / or create) dataset of unmerged samples\n",
    "    untrained_vocab = MusicVocab()\n",
    "    untrained_vocab_size = untrained_vocab.initial_size\n",
    "    untrained_vocab.train(None, untrained_vocab_size) # Required to init actions, not adding any tokens\n",
    "    print(f'Untrained vocab size: {untrained_vocab_size}')\n",
    "    vocab_training_dataset = MidiDataset(untrained_vocab, midi_file_paths, score_path, sample_length, max_file_length)\n",
    "    print(f\"Loading unmerged samples...\")\n",
    "    vocab_training_dataset.load_samples(False, \"cpu\")\n",
    "\n",
    "    # Train the vocab on the unmerged dataset, so it can learn the merges\n",
    "    print(f\"Training vocab, adding {max_vocab_size - untrained_vocab_size} tokens...\")\n",
    "    trained_vocab = MusicVocab()\n",
    "    trained_vocab.train(vocab_training_dataset, max_vocab_size=max_vocab_size)\n",
    "    print(f'Trained vocab size: {trained_vocab.size}')\n",
    "    print(f\"Saving vocab with actions:\\n{trained_vocab.actions}\")\n",
    "    trained_vocab.save(vocab_state_dict_path)\n",
    "else:\n",
    "    print(f\"Loading vocab...\")\n",
    "    trained_vocab = MusicVocab()\n",
    "    trained_vocab.load(vocab_state_dict_path)\n",
    "    print(f\"Loaded vocab with actions:\\n{trained_vocab.actions}\")\n",
    "    print(f'Trained vocab size: {trained_vocab.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading valid samples\n",
      "Loading test samples\n"
     ]
    }
   ],
   "source": [
    "merged_score_path = Path(f'../data/numpy/{vocab_name}')\n",
    "os.makedirs(merged_score_path, exist_ok=True)\n",
    "\n",
    "# Use the trained vocab to load GPU datasets, which will create merged samples if we pass a new path\n",
    "train_dataset = MidiDataset(trained_vocab, train_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "valid_dataset = MidiDataset(trained_vocab, valid_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "test_dataset = MidiDataset(trained_vocab, test_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "\n",
    "print(f'Loading train samples')\n",
    "train_dataset.load_samples(False, device)\n",
    "\n",
    "print(f'Loading valid samples')\n",
    "valid_dataset.load_samples(False, device)\n",
    "\n",
    "print(f'Loading test samples')\n",
    "test_dataset.load_samples(False, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 2198, Valid files: 275, Test files: 282\n"
     ]
    }
   ],
   "source": [
    "print(f'Train files: {len(train_dataset.file_lengths)}, Valid files: {len(valid_dataset.file_lengths)}, Test files: {len(test_dataset.file_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing indices\n"
     ]
    }
   ],
   "source": [
    "# Batch size can be changed for a second phase of training quite quickly, it only requires re-computing the indices, not re-loading the data.\n",
    "batch_size = 32\n",
    "train_sampler = ContiguousBatchSampler(train_dataset)\n",
    "valid_sampler = ContiguousBatchSampler(valid_dataset)\n",
    "test_sampler = ContiguousBatchSampler(test_dataset)\n",
    "\n",
    "print(f'Precomputing indices')\n",
    "train_sampler.precompute_indices(batch_size)\n",
    "valid_sampler.precompute_indices(batch_size)\n",
    "test_sampler.precompute_indices(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'midi_transformer_knn-xl_{vocab_name}-large-temp'\n",
    "model_load_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "model_save_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "log_dir = Path(f'../tensorboard/{model_name}')\n",
    "tensorboard_writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26147725\n"
     ]
    }
   ],
   "source": [
    "model = DecoderTransformer_KNN_XL(vocab=trained_vocab, sample_length=sample_length, max_file_length=max_file_length, device=device, use_knn=True, n_embed=512, n_head=8, n_layer=8)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "token_embedding.weight \t torch.Size([389, 512])\n",
      "rel_pos.relative_attention_embedding.weight \t torch.Size([32, 8])\n",
      "rel_pos_knn.relative_attention_embedding.weight \t torch.Size([32, 8])\n",
      "beat_embedding.weight \t torch.Size([32, 512])\n",
      "bar_embedding.weight \t torch.Size([1024, 512])\n",
      "blocks.0.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.project.bias \t torch.Size([512])\n",
      "blocks.0.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.0.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.0.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.0.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.0.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.0.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.0.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.0.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.1.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.project.bias \t torch.Size([512])\n",
      "blocks.1.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.1.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.1.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.1.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.1.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.1.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.1.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.1.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.2.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.project.bias \t torch.Size([512])\n",
      "blocks.2.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.2.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.2.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.2.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.2.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.2.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.2.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.2.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.3.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.project.bias \t torch.Size([512])\n",
      "blocks.3.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.3.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.3.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.3.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.3.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.3.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.3.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.3.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.4.attention.gate_bias \t torch.Size([8, 1, 1])\n",
      "blocks.4.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.project.bias \t torch.Size([512])\n",
      "blocks.4.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.4.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.4.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.4.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.4.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.4.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.4.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.4.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.5.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.project.bias \t torch.Size([512])\n",
      "blocks.5.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.5.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.5.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.5.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.5.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.5.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.5.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.5.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.6.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.project.bias \t torch.Size([512])\n",
      "blocks.6.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.6.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.6.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.6.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.6.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.6.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.6.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.6.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.7.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.project.bias \t torch.Size([512])\n",
      "blocks.7.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.7.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.7.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.7.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.7.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.7.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.7.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.7.layer_norm2.bias \t torch.Size([512])\n",
      "layer_norm.weight \t torch.Size([512])\n",
      "layer_norm.bias \t torch.Size([512])\n",
      "lm_head.weight \t torch.Size([389, 512])\n",
      "lm_head.bias \t torch.Size([389])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "eval_iters = 100\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    xl_memories = None\n",
    "    losses = torch.zeros(eval_iters)\n",
    "\n",
    "    for k in range(eval_iters):\n",
    "        file_idxs, batch = next(data_loader)\n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0] # drop absolute position from Y\n",
    "        _, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "        losses[k] = loss.item()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_log_losses = {  \n",
    "    \"train\" : [],\n",
    "    \"val\" : []\n",
    "}\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "train_loader_eval = cycle(DataLoader(train_dataset, batch_sampler=train_sampler))\n",
    "valid_loader_eval = cycle(DataLoader(valid_dataset, batch_sampler=valid_sampler))\n",
    "\n",
    "def save_checkpoint(iterations):\n",
    "    train_loss = estimate_loss(train_loader_eval)\n",
    "    val_loss = estimate_loss(valid_loader_eval)\n",
    "    tensorboard_writer.add_scalar('Loss/train', train_loss, iterations)\n",
    "    tensorboard_writer.add_scalar('Loss/val', val_loss, iterations)\n",
    "    train_log_loss = train_loss.log10().item()\n",
    "    val_log_loss = val_loss.log10().item()\n",
    "    average_log_losses['train'].append(train_log_loss)\n",
    "    average_log_losses['val'].append(val_log_loss)\n",
    "    print(f'Epoch {epochs} / Iteration {iterations}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    torch.save({\n",
    "        'iter': iterations,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'vocab_state_dict': trained_vocab.state_dict(),\n",
    "        'losses': average_log_losses,\n",
    "        'epochs': epochs\n",
    "    }, model_save_path)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from iteration 19600\n"
     ]
    }
   ],
   "source": [
    "eval_interval = 200\n",
    "total_iterations = 40000\n",
    "start_iter = 0\n",
    "\n",
    "if model_load_path.exists():\n",
    "    checkpoint = torch.load(model_load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    average_log_losses = checkpoint['losses']\n",
    "    iterations = checkpoint['iter']\n",
    "    epochs = checkpoint['epochs']\n",
    "    start_iter = iterations + 1\n",
    "    print(f\"Loaded model from iteration {iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from epoch 56 for 20399 iterations\n",
      "Epoch 58 / Iteration 19800: Train Loss: 1.0938, Val Loss: 1.1280\n",
      "Epoch 58 / Iteration 20000: Train Loss: 1.0600, Val Loss: 1.1243\n",
      "Epoch 58 / Iteration 20200: Train Loss: 1.1115, Val Loss: 1.1336\n",
      "Epoch 60 / Iteration 20400: Train Loss: 1.1241, Val Loss: 1.1184\n",
      "Epoch 60 / Iteration 20600: Train Loss: 1.1079, Val Loss: 1.1155\n",
      "Epoch 60 / Iteration 20800: Train Loss: 1.0915, Val Loss: 1.1016\n",
      "Epoch 60 / Iteration 21000: Train Loss: 1.0379, Val Loss: 1.1061\n",
      "Epoch 62 / Iteration 21200: Train Loss: 1.0724, Val Loss: 1.1217\n",
      "Epoch 62 / Iteration 21400: Train Loss: 1.0433, Val Loss: 1.1097\n",
      "Epoch 62 / Iteration 21600: Train Loss: 1.0938, Val Loss: 1.1134\n",
      "Epoch 64 / Iteration 21800: Train Loss: 1.1059, Val Loss: 1.1059\n",
      "Epoch 64 / Iteration 22000: Train Loss: 1.0946, Val Loss: 1.1030\n",
      "Epoch 64 / Iteration 22200: Train Loss: 1.0986, Val Loss: 1.1061\n",
      "Epoch 64 / Iteration 22400: Train Loss: 1.0342, Val Loss: 1.0964\n",
      "Epoch 66 / Iteration 22600: Train Loss: 1.0477, Val Loss: 1.0874\n",
      "Epoch 66 / Iteration 22800: Train Loss: 1.0264, Val Loss: 1.1026\n",
      "Epoch 66 / Iteration 23000: Train Loss: 1.0776, Val Loss: 1.0986\n",
      "Epoch 68 / Iteration 23200: Train Loss: 1.0870, Val Loss: 1.0946\n",
      "Epoch 68 / Iteration 23400: Train Loss: 1.0879, Val Loss: 1.0887\n",
      "Epoch 68 / Iteration 23600: Train Loss: 1.0817, Val Loss: 1.0868\n",
      "Epoch 68 / Iteration 23800: Train Loss: 1.0198, Val Loss: 1.0906\n",
      "Epoch 70 / Iteration 24000: Train Loss: 1.0343, Val Loss: 1.0786\n",
      "Epoch 70 / Iteration 24200: Train Loss: 1.0320, Val Loss: 1.0887\n",
      "Epoch 70 / Iteration 24400: Train Loss: 1.0592, Val Loss: 1.0844\n",
      "Epoch 72 / Iteration 24600: Train Loss: 1.0907, Val Loss: 1.1080\n",
      "Epoch 72 / Iteration 24800: Train Loss: 1.0887, Val Loss: 1.0859\n",
      "Epoch 72 / Iteration 25000: Train Loss: 1.0836, Val Loss: 1.0815\n",
      "Epoch 72 / Iteration 25200: Train Loss: 1.0115, Val Loss: 1.0791\n",
      "Epoch 74 / Iteration 25400: Train Loss: 1.0364, Val Loss: 1.0869\n",
      "Epoch 74 / Iteration 25600: Train Loss: 1.0229, Val Loss: 1.0847\n",
      "Epoch 74 / Iteration 25800: Train Loss: 1.0466, Val Loss: 1.0725\n",
      "Epoch 76 / Iteration 26000: Train Loss: 1.0606, Val Loss: 1.0660\n",
      "Epoch 76 / Iteration 26200: Train Loss: 1.0914, Val Loss: 1.0926\n",
      "Epoch 76 / Iteration 26400: Train Loss: 1.0696, Val Loss: 1.0793\n",
      "Epoch 76 / Iteration 26600: Train Loss: 0.9954, Val Loss: 1.0522\n",
      "Epoch 78 / Iteration 26800: Train Loss: 1.0159, Val Loss: 1.0574\n",
      "Epoch 78 / Iteration 27000: Train Loss: 1.0079, Val Loss: 1.0657\n",
      "Epoch 78 / Iteration 27200: Train Loss: 1.0229, Val Loss: 1.0693\n",
      "Epoch 80 / Iteration 27400: Train Loss: 1.0499, Val Loss: 1.0583\n",
      "Epoch 80 / Iteration 27600: Train Loss: 1.0723, Val Loss: 1.0556\n",
      "Epoch 80 / Iteration 27800: Train Loss: 1.0587, Val Loss: 1.0638\n",
      "Epoch 80 / Iteration 28000: Train Loss: 1.0176, Val Loss: 1.0814\n",
      "Epoch 82 / Iteration 28200: Train Loss: 1.0051, Val Loss: 1.0544\n",
      "Epoch 82 / Iteration 28400: Train Loss: 1.0028, Val Loss: 1.0602\n",
      "Epoch 82 / Iteration 28600: Train Loss: 1.0191, Val Loss: 1.0624\n",
      "Epoch 82 / Iteration 28800: Train Loss: 1.0601, Val Loss: 1.0725\n",
      "Epoch 84 / Iteration 29000: Train Loss: 1.0783, Val Loss: 1.0694\n",
      "Epoch 84 / Iteration 29200: Train Loss: 1.0494, Val Loss: 1.0464\n",
      "Epoch 84 / Iteration 29400: Train Loss: 0.9939, Val Loss: 1.0453\n",
      "Epoch 86 / Iteration 29600: Train Loss: 0.9965, Val Loss: 1.0489\n",
      "Epoch 86 / Iteration 29800: Train Loss: 0.9935, Val Loss: 1.0513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9722/3895695963.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/7 - Putting it together/model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch_file_idxs, x, xl_memories, targets)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mnew_xl_memories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misKNNLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_pos_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_mode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/7 - Putting it together/model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch_file_idxs, relative_positions, x, xl_memory, inference_mode)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Residual connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mattn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_xl_memories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_positions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxl_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_xl_memories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/7 - Putting it together/model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch_file_idxs, relative_positions, x, xl_memory, inference_mode)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_file_idxs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_file_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;31m# print(f'Clearing knn memory for batch dim {i}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_file_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_file_idxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/7 - Putting it together/model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  11522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11523\u001b[0m         \u001b[0;34mr\"\"\" Clears all vectors from this index\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGpuIndexFlat_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "remaining_iters = total_iterations - start_iter\n",
    "if remaining_iters != -1:\n",
    "    print(f\"Training from epoch {epochs} for {remaining_iters} iterations\")\n",
    "\n",
    "    train_data_loader = cycle(DataLoader(train_dataset, batch_sampler=train_sampler))\n",
    "    xl_memories = None\n",
    "    initial_file_idxs = None\n",
    "    offset_iter = start_iter\n",
    "\n",
    "    for iteration in range(remaining_iters):\n",
    "        offset_iter = iteration + start_iter\n",
    "\n",
    "        if offset_iter % eval_interval == 0:\n",
    "            save_checkpoint(offset_iter)\n",
    "            xl_memories = None\n",
    "\n",
    "        # Configure minibatch\n",
    "        file_idxs, batch = next(train_data_loader)\n",
    "\n",
    "        if initial_file_idxs is None:\n",
    "            initial_file_idxs = file_idxs\n",
    "\n",
    "        if torch.equal(initial_file_idxs, file_idxs):\n",
    "            epochs += 1\n",
    "        \n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0]\n",
    "\n",
    "        # Forward pass\n",
    "        logits, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    save_checkpoint(offset_iter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final training loss:', 10 ** average_log_losses['train'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final validation loss:', 10 ** average_log_losses['val'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['train'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['val'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_idx = torch.zeros((1,1,2), dtype=torch.long, device=device)\n",
    "generated_tokens = model.generate(init_idx, max_new_tokens=512).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = generated_tokens[0, :, 0]\n",
    "trained_vocab.to_tokens(score.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream = idx_to_stream_enc(np.array(score), trained_vocab)\n",
    "generated_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_path = random.choice(test_filepaths)\n",
    "print(random_test_path)\n",
    "random_test_idx_score = midifile_to_idx_score(random_test_path, trained_vocab)\n",
    "random_test_intro = random_test_idx_score[:sample_length]\n",
    "random_test_intro_stream = idx_to_stream_enc(np.array(random_test_intro[:, 0]), trained_vocab)\n",
    "random_test_intro_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_intro_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_init = torch.tensor(random_test_intro, device=device).unsqueeze(0)\n",
    "random_test_continued = model.generate(random_test_init, max_new_tokens=512).cpu()[0, :, 0]\n",
    "random_test_continued_stream = idx_to_stream_enc(np.array(random_test_continued), trained_vocab)\n",
    "random_test_continued_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_continued_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_timestep(data, include_position=False):\n",
    "    grouped = {}\n",
    "    for idx, position in data:\n",
    "        if position not in grouped:\n",
    "            grouped[position] = []\n",
    "        grouped[position].append(idx)\n",
    "    \n",
    "    if include_position:\n",
    "        result = [(tuple(values), position) for position, values in grouped.items()]\n",
    "    else:\n",
    "        result = [tuple(values) for values in grouped.values()]\n",
    "    return result\n",
    "\n",
    "data = [[1, 0], [2, 0], [3, 0], [4, 1], [5, 1], [6, 2], [7, 2], [8, 2], [9, 2]]\n",
    "\n",
    "grouped_data = group_by_timestep(data, include_position=False)\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = group_by_timestep(data, include_position=True)\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {}\n",
    "grouped_idxs = [(1, 2, 3), (4, 5), (6, 7, 8, 9), (1, 2, 3), (1, 2, 3), (6, 7, 8, 9), (4, 5), (4, 5), (4, 5)]\n",
    "for action in grouped_idxs:\n",
    "    actions[action] = actions.get(action, 0) + 1\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_actions = {k: v for k, v in sorted(actions.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_actions = list(sorted_actions.keys())[:2]\n",
    "top_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_size = 10\n",
    "\n",
    "def try_replace(action, position):\n",
    "    if action in top_actions:\n",
    "        return [[initial_size + top_actions.index(action)], position]\n",
    "    else:\n",
    "        return [list(action), position]\n",
    "        \n",
    "replaced_score = [try_replace(action, position) for action, position in grouped_data]\n",
    "replaced_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_idx_score = []\n",
    "pos_score = []\n",
    "for (action, position) in replaced_score:\n",
    "    for index in action:\n",
    "        note_idx_score.append(index)\n",
    "        pos_score.append(position)\n",
    "note_idx_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(top_actions):\n",
    "   print(' '.join([str(a) for a in action]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'7 - Putting it together')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from data_loading import *\n",
    "from model import *\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 10 19:45:21 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.51.01              Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   34C    P2             50W /  450W |    1678MiB /  24564MiB |     15%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        28      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        34      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178261"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'lakh_full_piano-vg_large'\n",
    "midi_path = Path(f'../data/midi/{dataset_name}')\n",
    "score_path = Path(f'../data/numpy/lakh_clean_piano-vg_large-actions_389') #Path(f'../data/numpy/{dataset_name}')\n",
    "midi_file_paths = list(midi_path.rglob('*.mid')) #[f for f in os.listdir(midi_path) if os.path.isfile(os.path.join(midi_path, f))]\n",
    "\n",
    "# Ensure files are shuffled directly after assignment.\n",
    "# If they are shuffled in a different cell, and that cell is run multiple times, the order will change as we are shuffling the already-shuffled list.\n",
    "random.seed(42)\n",
    "random.shuffle(midi_file_paths)\n",
    "\n",
    "len(midi_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file names: 142608, Valid file names: 17826, Test file names: 17827\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * len(midi_file_paths))\n",
    "n2 = int(0.9 * len(midi_file_paths))\n",
    "train_filepaths = midi_file_paths[:n1]\n",
    "valid_filepaths = midi_file_paths[n1:n2]\n",
    "test_filepaths = midi_file_paths[n2:]\n",
    "\n",
    "print(f'Train file names: {len(train_filepaths)}, Valid file names: {len(valid_filepaths)}, Test file names: {len(test_filepaths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 800\n",
    "vocab_name = f'{dataset_name}-actions_{max_vocab_size}'\n",
    "vocab_state_dict_path = Path(f'../data/vocab/{vocab_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MidiDataset says \"Look for the given filenames at the given score path. Load if they exist, if not create them'.\n",
    "\n",
    "We can use this to encode with the trained vocab if we pass it in as a param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n",
      "Loaded vocab with actions:\n",
      "[(47, 136, 3, 136), (52, 136, 3, 136), (54, 136, 3, 136), (49, 136, 3, 136), (45, 136, 3, 136), (59, 136, 3, 136), (56, 136, 3, 136), (61, 136, 3, 136), (40, 136, 3, 136), (44, 136, 3, 136), (64, 136, 3, 136), (66, 136, 3, 136), (57, 136, 3, 136), (51, 136, 3, 136), (50, 136, 3, 136), (42, 136, 3, 136), (47, 134, 3, 134), (68, 136, 3, 136), (46, 136, 3, 136), (71, 136, 3, 136), (63, 136, 3, 136), (48, 136, 3, 136), (73, 136, 3, 136), (52, 134, 3, 134), (54, 134, 3, 134), (49, 134, 3, 134), (76, 136, 3, 136), (78, 134, 3, 134), (55, 136, 3, 136), (71, 134, 3, 134), (44, 134, 3, 134), (59, 134, 3, 134), (69, 136, 3, 136), (73, 134, 3, 134), (78, 136, 3, 136), (80, 134, 3, 134), (43, 136, 3, 136), (58, 136, 3, 136), (76, 134, 3, 134), (53, 136, 3, 136), (62, 136, 3, 136), (66, 134, 3, 134), (45, 134, 3, 134), (47, 134, 3, 136), (83, 136, 3, 136), (75, 136, 3, 136), (64, 134, 3, 134), (80, 136, 3, 136), (68, 134, 3, 134), (75, 134, 3, 134), (83, 134, 3, 134), (40, 134, 3, 134), (81, 134, 3, 134), (61, 134, 3, 134), (60, 136, 3, 136), (74, 134, 3, 134), (52, 134, 3, 136), (50, 134, 3, 134), (56, 134, 3, 134), (79, 134, 3, 134), (42, 134, 3, 134), (65, 136, 3, 136), (67, 136, 3, 136), (69, 134, 3, 134), (70, 136, 3, 136), (57, 134, 3, 134), (44, 134, 3, 136), (40, 134, 3, 136), (74, 136, 3, 136), (49, 134, 3, 136), (63, 134, 3, 134), (72, 134, 3, 134), (85, 136, 3, 136), (81, 136, 3, 136), (85, 134, 3, 134), (70, 134, 3, 134), (45, 134, 3, 136), (42, 134, 3, 136), (67, 134, 3, 134), (79, 136, 3, 136), (54, 134, 3, 136), (72, 136, 3, 136), (48, 134, 3, 134), (41, 136, 3, 136), (77, 136, 3, 136), (82, 134, 3, 134), (77, 134, 3, 134), (58, 134, 3, 134), (37, 136, 3, 136), (87, 134, 3, 134), (38, 136, 3, 136), (51, 134, 3, 134), (82, 136, 3, 136), (88, 134, 3, 134), (53, 134, 3, 134), (59, 134, 3, 136), (39, 136, 3, 136), (55, 134, 3, 134), (56, 134, 3, 136), (51, 134, 3, 136), (46, 134, 3, 134), (88, 136, 3, 136), (87, 136, 3, 136), (86, 134, 3, 134), (62, 134, 3, 134), (65, 134, 3, 134), (43, 134, 3, 134), (35, 136, 3, 136), (52, 140, 3, 140), (50, 134, 3, 136), (84, 136, 3, 136), (60, 134, 3, 134), (90, 136, 3, 136), (84, 134, 3, 134), (86, 136, 3, 136), (61, 134, 3, 136), (46, 134, 3, 136), (71, 134, 3, 136), (53, 134, 3, 136), (64, 134, 59, 134, 3, 136), (64, 134, 3, 136), (90, 134, 3, 134), (48, 134, 3, 136), (57, 134, 3, 136), (41, 134, 3, 134), (47, 140, 3, 140), (73, 134, 3, 136), (55, 134, 3, 136), (54, 135, 3, 135), (36, 136, 3, 136), (63, 134, 3, 136), (39, 134, 3, 134), (76, 135, 3, 135), (47, 135, 3, 135), (78, 135, 3, 135), (43, 134, 3, 136), (76, 134, 3, 136), (44, 140, 3, 140), (78, 134, 3, 136), (80, 134, 3, 136), (37, 134, 3, 136), (92, 134, 3, 134), (35, 134, 3, 134), (37, 134, 3, 134), (73, 135, 3, 135), (71, 135, 3, 135), (54, 136, 42, 136, 3, 136), (49, 140, 3, 140), (92, 136, 3, 136), (54, 140, 3, 140), (66, 134, 3, 136), (58, 134, 3, 136), (60, 134, 3, 136), (38, 134, 3, 134), (62, 134, 3, 136), (89, 136, 3, 136), (52, 136, 40, 136, 3, 136), (45, 140, 3, 140), (89, 134, 3, 134), (59, 136, 47, 136, 3, 136), (78, 140, 3, 140), (80, 135, 3, 135), (75, 135, 3, 135), (41, 134, 3, 136), (35, 134, 3, 136), (47, 136, 3, 140), (47, 136, 3, 134), (69, 134, 3, 136), (56, 135, 3, 135), (83, 134, 3, 136), (52, 136, 3, 140), (71, 136, 47, 136, 3, 136), (71, 140, 3, 140), (95, 136, 3, 136), (73, 136, 61, 136, 3, 136), (33, 136, 3, 136), (68, 140, 3, 140), (93, 134, 3, 134), (52, 135, 3, 135), (68, 134, 3, 136), (64, 140, 3, 140), (68, 135, 3, 135), (49, 135, 3, 135), (76, 140, 3, 140), (59, 140, 3, 140), (85, 134, 3, 136), (91, 136, 3, 136), (76, 134, 52, 134, 3, 134), (81, 134, 3, 136), (75, 134, 3, 136), (66, 140, 3, 140), (61, 135, 3, 135), (38, 134, 3, 136), (59, 134, 54, 134, 3, 136), (42, 136, 3, 140), (83, 140, 3, 140), (57, 136, 45, 136, 3, 136), (93, 136, 3, 136), (42, 140, 3, 140), (64, 134, 61, 134, 3, 136), (63, 135, 3, 135), (59, 134, 56, 134, 3, 136), (59, 135, 3, 135), (40, 135, 3, 135), (74, 135, 3, 135), (64, 135, 3, 135), (59, 136, 56, 136, 3, 136), (51, 140, 3, 140), (92, 134, 87, 134, 3, 136), (83, 135, 3, 135), (54, 136, 3, 140), (39, 134, 3, 136), (66, 135, 3, 135), (76, 136, 52, 136, 3, 136), (45, 136, 3, 140), (73, 136, 49, 136, 3, 136), (73, 140, 3, 140), (66, 134, 63, 134, 3, 136), (74, 134, 3, 136), (56, 140, 3, 140), (63, 134, 59, 134, 3, 136), (51, 135, 3, 135), (91, 134, 3, 134), (52, 136, 3, 134), (49, 136, 3, 134), (64, 134, 60, 134, 3, 136), (52, 134, 40, 134, 3, 136), (68, 134, 64, 134, 3, 136), (64, 136, 59, 136, 3, 136), (40, 140, 3, 140), (83, 136, 47, 136, 3, 136), (70, 134, 3, 136), (42, 136, 3, 134), (72, 134, 3, 136), (64, 134, 59, 134, 3, 134), (42, 135, 3, 135), (33, 134, 3, 134), (61, 140, 3, 140), (69, 135, 3, 135), (77, 134, 3, 136), (71, 136, 59, 136, 3, 136), (44, 136, 3, 140), (50, 140, 3, 140), (59, 136, 52, 136, 3, 136), (75, 140, 3, 140), (61, 136, 49, 136, 3, 136), (52, 140, 3, 136), (72, 135, 3, 135), (54, 134, 49, 134, 3, 136), (54, 136, 3, 134), (64, 136, 52, 136, 3, 136), (67, 134, 3, 136), (61, 134, 56, 134, 3, 134), (95, 134, 3, 134), (71, 136, 66, 136, 3, 136), (56, 136, 44, 136, 3, 136), (48, 140, 3, 140), (59, 136, 54, 136, 3, 136), (57, 140, 3, 140), (61, 134, 58, 134, 3, 136), (67, 136, 64, 136, 3, 136), (40, 136, 3, 140), (81, 135, 3, 135), (80, 140, 3, 140), (55, 140, 3, 140), (36, 134, 3, 134), (88, 134, 3, 136), (81, 140, 3, 140), (78, 136, 54, 136, 3, 136), (59, 134, 47, 134, 3, 136), (82, 134, 3, 136), (66, 134, 61, 134, 3, 136), (33, 134, 3, 136), (82, 135, 3, 135), (78, 136, 66, 136, 3, 136), (78, 134, 76, 134, 3, 134), (76, 136, 64, 136, 3, 136), (49, 136, 3, 140), (76, 134, 73, 134, 3, 134), (63, 140, 3, 140), (79, 134, 78, 134, 3, 134), (63, 136, 59, 136, 3, 136), (69, 140, 3, 140), (77, 135, 3, 135), (74, 140, 3, 140), (69, 136, 57, 136, 3, 136), (61, 134, 56, 134, 3, 136), (87, 134, 3, 136), (68, 136, 56, 136, 3, 136), (45, 136, 3, 134), (71, 134, 64, 134, 3, 136), (32, 134, 3, 134), (59, 136, 3, 134), (47, 140, 3, 136), (66, 136, 54, 136, 3, 136), (50, 136, 3, 140), (61, 136, 58, 136, 3, 136), (67, 135, 3, 135), (71, 134, 68, 134, 3, 136), (54, 136, 47, 136, 3, 136), (56, 134, 44, 134, 3, 136), (85, 140, 3, 140), (78, 136, 47, 136, 3, 136), (76, 136, 3, 134), (79, 135, 3, 135), (32, 136, 3, 136), (52, 135, 3, 134), (56, 136, 3, 134), (63, 134, 61, 134, 3, 136), (83, 134, 80, 134, 3, 134), (84, 134, 3, 136), (68, 136, 64, 136, 3, 136), (69, 136, 66, 136, 3, 136), (85, 135, 3, 135), (59, 136, 3, 140), (40, 136, 3, 134), (36, 134, 3, 136), (34, 136, 3, 136), (66, 134, 62, 134, 3, 136), (78, 136, 3, 134), (57, 134, 45, 134, 3, 134), (64, 136, 61, 136, 3, 136), (79, 134, 3, 136), (69, 136, 45, 136, 3, 136), (49, 140, 3, 136), (44, 135, 3, 135), (75, 136, 51, 136, 3, 136), (42, 138, 3, 138), (94, 136, 3, 136), (66, 136, 62, 136, 3, 136), (71, 136, 68, 136, 3, 136), (80, 134, 76, 134, 3, 134), (61, 136, 56, 136, 3, 136), (56, 136, 3, 140), (68, 136, 63, 136, 3, 136), (71, 134, 66, 134, 3, 136), (46, 140, 3, 140), (70, 135, 3, 135), (63, 134, 60, 134, 3, 136), (76, 136, 71, 136, 3, 136), (61, 136, 3, 134), (73, 140, 3, 136), (71, 136, 3, 134), (44, 140, 3, 136), (61, 134, 49, 134, 3, 136), (58, 140, 3, 140), (47, 138, 3, 138), (52, 134, 47, 134, 3, 136), (63, 135, 3, 134), (79, 140, 3, 140), (59, 136, 55, 136, 3, 136), (46, 135, 3, 135), (61, 136, 57, 136, 3, 136), (63, 136, 3, 134), (84, 134, 83, 134, 3, 134), (57, 134, 52, 134, 3, 136), (85, 134, 83, 134, 3, 134), (52, 136, 40, 136, 3, 140), (64, 136, 3, 134), (71, 140, 3, 136), (64, 134, 61, 134, 3, 134), (76, 134, 64, 134, 3, 134), (80, 134, 78, 134, 3, 134), (57, 134, 45, 134, 3, 136), (57, 136, 52, 136, 3, 136), (51, 136, 39, 136, 3, 136), (55, 136, 48, 136, 3, 136), (73, 135, 3, 134), (40, 138, 3, 140), (53, 135, 3, 135), (88, 136, 76, 136, 3, 136), (57, 135, 3, 135), (78, 134, 75, 134, 3, 136), (75, 140, 3, 136), (66, 136, 61, 136, 3, 136), (59, 134, 55, 134, 3, 136), (59, 140, 3, 136), (53, 140, 3, 140), (73, 136, 3, 134), (56, 140, 3, 136), (78, 134, 54, 134, 3, 134), (56, 134, 52, 134, 3, 136), (52, 136, 45, 136, 3, 136), (76, 140, 3, 136), (68, 136, 44, 136, 3, 136), (78, 134, 75, 134, 3, 134), (74, 134, 71, 134, 3, 134), (60, 135, 3, 135), (73, 136, 69, 136, 3, 136), (71, 134, 67, 134, 3, 134), (62, 135, 3, 135), (62, 134, 57, 134, 3, 136), (68, 134, 65, 134, 3, 136), (66, 136, 42, 136, 3, 136), (64, 136, 3, 140), (80, 136, 56, 136, 3, 136), (71, 136, 52, 136, 3, 136), (64, 134, 52, 134, 3, 136), (39, 135, 3, 135), (71, 134, 66, 134, 3, 134), (65, 134, 3, 136), (97, 136, 3, 136), (34, 134, 3, 134), (34, 134, 3, 136), (62, 134, 59, 134, 3, 136), (54, 140, 3, 136), (80, 136, 68, 136, 3, 136), (59, 134, 47, 134, 3, 134), (48, 135, 3, 135), (70, 136, 66, 136, 3, 136), (71, 134, 67, 134, 3, 136)]\n",
      "Trained vocab size: 800\n"
     ]
    }
   ],
   "source": [
    "sample_length = 256\n",
    "max_file_length = 32\n",
    "\n",
    "if not vocab_state_dict_path.exists():\n",
    "    \n",
    "    # Load (and / or create) dataset of unmerged samples\n",
    "    untrained_vocab = MusicVocab()\n",
    "    untrained_vocab_size = untrained_vocab.initial_size\n",
    "    untrained_vocab.train(None, untrained_vocab_size) # Required to init actions, not adding any tokens\n",
    "    print(f'Untrained vocab size: {untrained_vocab_size}')\n",
    "    vocab_training_dataset = MidiDataset(untrained_vocab, midi_file_paths, score_path, sample_length, max_file_length)\n",
    "    print(f\"Loading unmerged samples...\")\n",
    "    vocab_training_dataset.load_samples(False, \"cpu\")\n",
    "\n",
    "    # Train the vocab on the unmerged dataset, so it can learn the merges\n",
    "    print(f\"Training vocab, adding {max_vocab_size - untrained_vocab_size} tokens...\")\n",
    "    trained_vocab = MusicVocab()\n",
    "    trained_vocab.train(vocab_training_dataset, max_vocab_size=max_vocab_size)\n",
    "    print(f'Trained vocab size: {trained_vocab.size}')\n",
    "    print(f\"Saving vocab with actions:\\n{trained_vocab.actions}\")\n",
    "    trained_vocab.save(vocab_state_dict_path)\n",
    "else:\n",
    "    print(f\"Loading vocab...\")\n",
    "    trained_vocab = MusicVocab()\n",
    "    trained_vocab.load(vocab_state_dict_path)\n",
    "    print(f\"Loaded vocab with actions:\\n{trained_vocab.actions}\")\n",
    "    print(f'Trained vocab size: {trained_vocab.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train samples\n",
      "Error loading file ../data/numpy/lakh_full_piano-vg_large-actions_800/d681976c7b45d9fa9f98abb4f7f088a8.npy: Failed to interpret file PosixPath('../data/numpy/lakh_full_piano-vg_large-actions_800/d681976c7b45d9fa9f98abb4f7f088a8.npy') as a pickle\n",
      "Error loading file ../data/numpy/lakh_full_piano-vg_large-actions_800/caa0e973f2c19b2e1f56d4178be20a0d.npy: Failed to interpret file PosixPath('../data/numpy/lakh_full_piano-vg_large-actions_800/caa0e973f2c19b2e1f56d4178be20a0d.npy') as a pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading valid samples\n",
      "Loading test samples\n"
     ]
    }
   ],
   "source": [
    "merged_score_path = Path(f'../data/numpy/{vocab_name}')\n",
    "os.makedirs(merged_score_path, exist_ok=True)\n",
    "\n",
    "# Use the trained vocab to load GPU datasets, which will create merged samples if we pass a new path\n",
    "train_dataset = MidiDataset(trained_vocab, train_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "valid_dataset = MidiDataset(trained_vocab, valid_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "test_dataset = MidiDataset(trained_vocab, test_filepaths, merged_score_path, sample_length, max_file_length)\n",
    "\n",
    "print(f'Loading train samples')\n",
    "train_dataset.load_samples(False, device)\n",
    "\n",
    "print(f'Loading valid samples')\n",
    "valid_dataset.load_samples(False, device)\n",
    "\n",
    "print(f'Loading test samples')\n",
    "test_dataset.load_samples(False, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 77113, Valid files: 9491, Test files: 9635\n"
     ]
    }
   ],
   "source": [
    "print(f'Train files: {len(train_dataset.file_lengths)}, Valid files: {len(valid_dataset.file_lengths)}, Test files: {len(test_dataset.file_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing indices\n"
     ]
    }
   ],
   "source": [
    "# Batch size can be changed for a second phase of training quite quickly, it only requires re-computing the indices, not re-loading the data.\n",
    "batch_size = 32\n",
    "train_sampler = ContiguousBatchSampler(train_dataset)\n",
    "valid_sampler = ContiguousBatchSampler(valid_dataset)\n",
    "test_sampler = ContiguousBatchSampler(test_dataset)\n",
    "\n",
    "print(f'Precomputing indices')\n",
    "train_sampler.precompute_indices(batch_size)\n",
    "valid_sampler.precompute_indices(batch_size)\n",
    "test_sampler.precompute_indices(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'midi_transformer_knn-xl_{vocab_name}-large'\n",
    "model_load_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "model_save_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "log_dir = Path(f'../tensorboard/{model_name}')\n",
    "tensorboard_writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26569000\n"
     ]
    }
   ],
   "source": [
    "model = DecoderTransformer_KNN_XL(vocab=trained_vocab, sample_length=sample_length, max_file_length=max_file_length, device=device, use_knn=True, n_embed=512, n_head=8, n_layer=8)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "token_embedding.weight \t torch.Size([800, 512])\n",
      "rel_pos.relative_attention_embedding.weight \t torch.Size([32, 8])\n",
      "rel_pos_knn.relative_attention_embedding.weight \t torch.Size([32, 8])\n",
      "beat_embedding.weight \t torch.Size([32, 512])\n",
      "bar_embedding.weight \t torch.Size([1024, 512])\n",
      "blocks.0.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.0.attention.project.bias \t torch.Size([512])\n",
      "blocks.0.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.0.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.0.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.0.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.0.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.0.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.0.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.0.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.1.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.1.attention.project.bias \t torch.Size([512])\n",
      "blocks.1.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.1.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.1.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.1.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.1.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.1.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.1.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.1.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.2.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.2.attention.project.bias \t torch.Size([512])\n",
      "blocks.2.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.2.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.2.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.2.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.2.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.2.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.2.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.2.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.3.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.3.attention.project.bias \t torch.Size([512])\n",
      "blocks.3.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.3.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.3.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.3.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.3.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.3.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.3.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.3.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.4.attention.gate_bias \t torch.Size([8, 1, 1])\n",
      "blocks.4.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.4.attention.project.bias \t torch.Size([512])\n",
      "blocks.4.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.4.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.4.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.4.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.4.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.4.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.4.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.4.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.5.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.5.attention.project.bias \t torch.Size([512])\n",
      "blocks.5.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.5.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.5.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.5.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.5.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.5.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.5.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.5.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.6.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.6.attention.project.bias \t torch.Size([512])\n",
      "blocks.6.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.6.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.6.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.6.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.6.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.6.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.6.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.6.layer_norm2.bias \t torch.Size([512])\n",
      "blocks.7.attention.key.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.query.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.value.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.project.weight \t torch.Size([512, 512])\n",
      "blocks.7.attention.project.bias \t torch.Size([512])\n",
      "blocks.7.ff.net.0.weight \t torch.Size([2048, 512])\n",
      "blocks.7.ff.net.0.bias \t torch.Size([2048])\n",
      "blocks.7.ff.net.3.weight \t torch.Size([512, 2048])\n",
      "blocks.7.ff.net.3.bias \t torch.Size([512])\n",
      "blocks.7.layer_norm1.weight \t torch.Size([512])\n",
      "blocks.7.layer_norm1.bias \t torch.Size([512])\n",
      "blocks.7.layer_norm2.weight \t torch.Size([512])\n",
      "blocks.7.layer_norm2.bias \t torch.Size([512])\n",
      "layer_norm.weight \t torch.Size([512])\n",
      "layer_norm.bias \t torch.Size([512])\n",
      "lm_head.weight \t torch.Size([800, 512])\n",
      "lm_head.bias \t torch.Size([800])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "eval_iters = 100\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    xl_memories = None\n",
    "    losses = torch.zeros(eval_iters)\n",
    "\n",
    "    for k in range(eval_iters):\n",
    "        file_idxs, batch = next(data_loader)\n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0] # drop absolute position from Y\n",
    "        _, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "        losses[k] = loss.item()\n",
    "\n",
    "    del xl_memories\n",
    "    model.train()\n",
    "    \n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_log_losses = {  \n",
    "    \"train\" : [],\n",
    "    \"val\" : []\n",
    "}\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "train_loader_eval = cycle(DataLoader(train_dataset, batch_sampler=train_sampler))\n",
    "valid_loader_eval = cycle(DataLoader(valid_dataset, batch_sampler=valid_sampler))\n",
    "\n",
    "def save_checkpoint(iterations):\n",
    "    train_loss = estimate_loss(train_loader_eval)\n",
    "    val_loss = estimate_loss(valid_loader_eval)\n",
    "    tensorboard_writer.add_scalar('Loss/train', train_loss, iterations)\n",
    "    tensorboard_writer.add_scalar('Loss/val', val_loss, iterations)\n",
    "    train_log_loss = train_loss.log10().item()\n",
    "    val_log_loss = val_loss.log10().item()\n",
    "    average_log_losses['train'].append(train_log_loss)\n",
    "    average_log_losses['val'].append(val_log_loss)\n",
    "    print(f'Epoch {epochs} / Iteration {iterations}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    torch.save({\n",
    "        'iter': iterations,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'vocab_state_dict': trained_vocab.state_dict(),\n",
    "        'losses': average_log_losses,\n",
    "        'epochs': epochs\n",
    "    }, model_save_path)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/checkpoints/midi_transformer_knn-xl_lakh_full_piano-vg_large-actions_800-large.dat\n",
      "Loaded model from iteration 352800\n"
     ]
    }
   ],
   "source": [
    "eval_interval = 800\n",
    "total_iterations = 1000000\n",
    "start_iter = 0\n",
    "print(model_load_path)\n",
    "if model_load_path.exists():\n",
    "    checkpoint = torch.load(model_load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    average_log_losses = checkpoint['losses']\n",
    "    iterations = checkpoint['iter']\n",
    "    epochs = checkpoint['epochs']\n",
    "    start_iter = iterations + 1\n",
    "    print(f\"Loaded model from iteration {iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from epoch 12 for 647199 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  x.storage().data_ptr() + x.storage_offset() * 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / Iteration 353600: Train Loss: 1.3755, Val Loss: 1.4249\n",
      "Epoch 13 / Iteration 354400: Train Loss: 1.4429, Val Loss: 1.4809\n",
      "Epoch 13 / Iteration 355200: Train Loss: 1.4236, Val Loss: 1.4208\n",
      "Epoch 13 / Iteration 356000: Train Loss: 1.3781, Val Loss: 1.3739\n",
      "Epoch 13 / Iteration 356800: Train Loss: 1.4222, Val Loss: 1.3941\n",
      "Epoch 13 / Iteration 357600: Train Loss: 1.4206, Val Loss: 1.4571\n",
      "Epoch 13 / Iteration 358400: Train Loss: 1.4167, Val Loss: 1.4278\n",
      "Epoch 13 / Iteration 359200: Train Loss: 1.4233, Val Loss: 1.3971\n",
      "Epoch 13 / Iteration 360000: Train Loss: 1.4613, Val Loss: 1.4127\n",
      "Epoch 13 / Iteration 360800: Train Loss: 1.3903, Val Loss: 1.4426\n",
      "Epoch 13 / Iteration 361600: Train Loss: 1.4291, Val Loss: 1.3907\n",
      "Epoch 13 / Iteration 362400: Train Loss: 1.4240, Val Loss: 1.3886\n",
      "Epoch 13 / Iteration 363200: Train Loss: 1.4333, Val Loss: 1.3859\n",
      "Epoch 13 / Iteration 364000: Train Loss: 1.4063, Val Loss: 1.3958\n",
      "Epoch 13 / Iteration 364800: Train Loss: 1.3657, Val Loss: 1.4347\n",
      "Epoch 13 / Iteration 365600: Train Loss: 1.4078, Val Loss: 1.4265\n",
      "Epoch 13 / Iteration 366400: Train Loss: 1.4485, Val Loss: 1.4397\n",
      "Epoch 13 / Iteration 367200: Train Loss: 1.4006, Val Loss: 1.3978\n",
      "Epoch 13 / Iteration 368000: Train Loss: 1.4054, Val Loss: 1.4034\n",
      "Epoch 13 / Iteration 368800: Train Loss: 1.4272, Val Loss: 1.4332\n",
      "Epoch 13 / Iteration 369600: Train Loss: 1.3995, Val Loss: 1.4567\n",
      "Epoch 13 / Iteration 370400: Train Loss: 1.3958, Val Loss: 1.4065\n",
      "Epoch 13 / Iteration 371200: Train Loss: 1.3887, Val Loss: 1.4611\n",
      "Epoch 13 / Iteration 372000: Train Loss: 1.3912, Val Loss: 1.4399\n",
      "Epoch 13 / Iteration 372800: Train Loss: 1.3981, Val Loss: 1.4348\n",
      "Epoch 13 / Iteration 373600: Train Loss: 1.3734, Val Loss: 1.4301\n",
      "Epoch 13 / Iteration 374400: Train Loss: 1.4042, Val Loss: 1.4334\n",
      "Epoch 13 / Iteration 375200: Train Loss: 1.4162, Val Loss: 1.3693\n",
      "Epoch 13 / Iteration 376000: Train Loss: 1.3777, Val Loss: 1.3875\n",
      "Epoch 13 / Iteration 376800: Train Loss: 1.3968, Val Loss: 1.3924\n",
      "Epoch 13 / Iteration 377600: Train Loss: 1.4312, Val Loss: 1.4181\n",
      "Epoch 13 / Iteration 378400: Train Loss: 1.4280, Val Loss: 1.4482\n",
      "Epoch 13 / Iteration 379200: Train Loss: 1.3888, Val Loss: 1.4196\n",
      "Epoch 13 / Iteration 380000: Train Loss: 1.4034, Val Loss: 1.4157\n",
      "Epoch 13 / Iteration 380800: Train Loss: 1.3889, Val Loss: 1.3666\n",
      "Epoch 13 / Iteration 381600: Train Loss: 1.4218, Val Loss: 1.3704\n",
      "Epoch 13 / Iteration 382400: Train Loss: 1.3560, Val Loss: 1.3834\n",
      "Epoch 13 / Iteration 383200: Train Loss: 1.4252, Val Loss: 1.4354\n",
      "Epoch 13 / Iteration 384000: Train Loss: 1.3871, Val Loss: 1.4318\n",
      "Epoch 13 / Iteration 384800: Train Loss: 1.3497, Val Loss: 1.4565\n",
      "Epoch 13 / Iteration 385600: Train Loss: 1.4051, Val Loss: 1.3878\n",
      "Epoch 13 / Iteration 386400: Train Loss: 1.3651, Val Loss: 1.4369\n",
      "Epoch 13 / Iteration 387200: Train Loss: 1.3870, Val Loss: 1.3867\n",
      "Epoch 13 / Iteration 388000: Train Loss: 1.4111, Val Loss: 1.4039\n",
      "Epoch 13 / Iteration 388800: Train Loss: 1.4364, Val Loss: 1.3971\n",
      "Epoch 13 / Iteration 389600: Train Loss: 1.5438, Val Loss: 1.4252\n",
      "Epoch 13 / Iteration 390400: Train Loss: 1.4358, Val Loss: 1.4009\n",
      "Epoch 14 / Iteration 391200: Train Loss: 1.4565, Val Loss: 1.4254\n",
      "Epoch 14 / Iteration 392000: Train Loss: 1.3889, Val Loss: 1.4880\n",
      "Epoch 14 / Iteration 392800: Train Loss: 1.3818, Val Loss: 1.4088\n",
      "Epoch 14 / Iteration 393600: Train Loss: 1.4671, Val Loss: 1.3820\n",
      "Epoch 14 / Iteration 394400: Train Loss: 1.4064, Val Loss: 1.3930\n",
      "Epoch 14 / Iteration 395200: Train Loss: 1.3992, Val Loss: 1.4486\n",
      "Epoch 14 / Iteration 396000: Train Loss: 1.4328, Val Loss: 1.4297\n",
      "Epoch 14 / Iteration 396800: Train Loss: 1.4094, Val Loss: 1.3958\n",
      "Epoch 14 / Iteration 397600: Train Loss: 1.3871, Val Loss: 1.4117\n",
      "Epoch 14 / Iteration 398400: Train Loss: 1.4035, Val Loss: 1.4489\n",
      "Epoch 14 / Iteration 399200: Train Loss: 1.3985, Val Loss: 1.3891\n",
      "Epoch 14 / Iteration 400000: Train Loss: 1.3441, Val Loss: 1.3909\n",
      "Epoch 14 / Iteration 400800: Train Loss: 1.4324, Val Loss: 1.3873\n",
      "Epoch 14 / Iteration 401600: Train Loss: 1.3784, Val Loss: 1.3978\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m batch[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], batch[:, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m logits, loss, xl_memories \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl_memories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/src/7 - Putting it together/model.py:490\u001b[0m, in \u001b[0;36mDecoderTransformer_KNN_XL.forward\u001b[0;34m(self, batch_file_idxs, x, xl_memories, targets)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misKNNLayer(i):\n\u001b[0;32m--> 490\u001b[0m         x, xl_mem \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_file_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_pos_knn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl_memories\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minference_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m         x, xl_mem \u001b[38;5;241m=\u001b[39m block(rel_pos, x, xl_memories[i])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/src/7 - Putting it together/model.py:384\u001b[0m, in \u001b[0;36mKNNBlock.forward\u001b[0;34m(self, batch_file_idxs, relative_positions, x, xl_memory, inference_mode)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_file_idxs, relative_positions, x, xl_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, inference_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# Residual connections\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     attn_out, new_xl_memories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_file_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_file_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxl_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m attn_out\n\u001b[1;32m    386\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2(x))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/src/7 - Putting it together/model.py:328\u001b[0m, in \u001b[0;36mKNN_XLAttention.forward\u001b[0;34m(self, batch_file_idxs, relative_positions, x, xl_memory, inference_mode)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknn[i]\u001b[38;5;241m.\u001b[39madd(trimmed_xl_memory)\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;66;03m# During training, we advance a whole sequence block at a time.\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_xl_memory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out), new_xl_memory\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/src/7 - Putting it together/model.py:42\u001b[0m, in \u001b[0;36mKNN.add\u001b[0;34m(self, new_data)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_data):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_to_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     keys, vals \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39munbind(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# Only keys are used in knn index\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39madd(keys\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcontiguous())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "remaining_iters = total_iterations - start_iter\n",
    "if remaining_iters != -1:\n",
    "    print(f\"Training from epoch {epochs} for {remaining_iters} iterations\")\n",
    "\n",
    "    train_data_loader = cycle(DataLoader(train_dataset, batch_sampler=train_sampler))\n",
    "    xl_memories = None\n",
    "    initial_file_idxs = None\n",
    "    offset_iter = start_iter\n",
    "\n",
    "    for iteration in range(remaining_iters):\n",
    "        offset_iter = iteration + start_iter\n",
    "\n",
    "        if offset_iter % eval_interval == 0:\n",
    "            save_checkpoint(offset_iter)\n",
    "            del xl_memories\n",
    "            xl_memories = None\n",
    "\n",
    "        # Configure minibatch\n",
    "        file_idxs, batch = next(train_data_loader)\n",
    "\n",
    "        if initial_file_idxs is None:\n",
    "            initial_file_idxs = file_idxs\n",
    " \n",
    "        if torch.equal(initial_file_idxs, file_idxs):\n",
    "            epochs += 1\n",
    "        \n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0]\n",
    "\n",
    "        # Forward pass\n",
    "        logits, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    save_checkpoint(offset_iter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final training loss:', 10 ** average_log_losses['train'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final validation loss:', 10 ** average_log_losses['val'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['train'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['val'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_idx = torch.zeros((1,1,2), dtype=torch.long, device=device)\n",
    "generated_tokens = model.generate(init_idx, max_new_tokens=512).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = generated_tokens[0, :, 0]\n",
    "trained_vocab.to_tokens(score.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream = idx_to_stream_enc(np.array(score), trained_vocab)\n",
    "generated_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_path = random.choice(test_filepaths)\n",
    "print(random_test_path)\n",
    "random_test_idx_score = midifile_to_idx_score(random_test_path, trained_vocab)\n",
    "random_test_intro = random_test_idx_score[:sample_length]\n",
    "random_test_intro_stream = idx_to_stream_enc(np.array(random_test_intro[:, 0]), trained_vocab)\n",
    "random_test_intro_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_intro_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_init = torch.tensor(random_test_intro, device=device).unsqueeze(0)\n",
    "random_test_continued = model.generate(random_test_init, max_new_tokens=512).cpu()[0, :, 0]\n",
    "random_test_continued_stream = idx_to_stream_enc(np.array(random_test_continued), trained_vocab)\n",
    "random_test_continued_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_continued_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_timestep(data, include_position=False):\n",
    "    grouped = {}\n",
    "    for idx, position in data:\n",
    "        if position not in grouped:\n",
    "            grouped[position] = []\n",
    "        grouped[position].append(idx)\n",
    "    \n",
    "    if include_position:\n",
    "        result = [(tuple(values), position) for position, values in grouped.items()]\n",
    "    else:\n",
    "        result = [tuple(values) for values in grouped.values()]\n",
    "    return result\n",
    "\n",
    "data = [[1, 0], [2, 0], [3, 0], [4, 1], [5, 1], [6, 2], [7, 2], [8, 2], [9, 2]]\n",
    "\n",
    "grouped_data = group_by_timestep(data, include_position=False)\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = group_by_timestep(data, include_position=True)\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {}\n",
    "grouped_idxs = [(1, 2, 3), (4, 5), (6, 7, 8, 9), (1, 2, 3), (1, 2, 3), (6, 7, 8, 9), (4, 5), (4, 5), (4, 5)]\n",
    "for action in grouped_idxs:\n",
    "    actions[action] = actions.get(action, 0) + 1\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_actions = {k: v for k, v in sorted(actions.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_actions = list(sorted_actions.keys())[:2]\n",
    "top_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_size = 10\n",
    "\n",
    "def try_replace(action, position):\n",
    "    if action in top_actions:\n",
    "        return [[initial_size + top_actions.index(action)], position]\n",
    "    else:\n",
    "        return [list(action), position]\n",
    "        \n",
    "replaced_score = [try_replace(action, position) for action, position in grouped_data]\n",
    "replaced_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_idx_score = []\n",
    "pos_score = []\n",
    "for (action, position) in replaced_score:\n",
    "    for index in action:\n",
    "        note_idx_score.append(index)\n",
    "        pos_score.append(position)\n",
    "note_idx_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(top_actions):\n",
    "   print(' '.join([str(a) for a in action]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

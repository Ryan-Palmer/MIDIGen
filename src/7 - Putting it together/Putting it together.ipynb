{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'7 - Putting it together')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from data_loading import *\n",
    "from model import *\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 10 19:21:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   33C    P2             48W /  450W |    3144MiB /  24564MiB |     38%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        29      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        31      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        41      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3839"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg_large_path = Path('../data/midi/vg_large')\n",
    "vg_large_file_names = [f for f in os.listdir(vg_large_path) if os.path.isfile(os.path.join(vg_large_path, f))]\n",
    "\n",
    "# Ensure files are shuffled directly after assignment.\n",
    "# If they are shuffled in a different cell, and that cell is run multiple times, the order will change as we are shuffling the already-shuffled list.\n",
    "random.seed(42)\n",
    "random.shuffle(vg_large_file_names)\n",
    "\n",
    "len(vg_large_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file names: 3071, Valid file names: 384, Test file names: 384\n"
     ]
    }
   ],
   "source": [
    "sample_length = 256\n",
    "max_file_length = 32\n",
    "\n",
    "midi_path = Path('../data/midi/vg_large')\n",
    "score_path = Path(f'../data/numpy/vg_large/all')\n",
    "\n",
    "n1 = int(0.8 * len(vg_large_file_names))\n",
    "n2 = int(0.9 * len(vg_large_file_names))\n",
    "train_filenames = vg_large_file_names[:n1]\n",
    "valid_filenames = vg_large_file_names[n1:n2]\n",
    "test_filenames = vg_large_file_names[n2:]\n",
    "\n",
    "print(f'Train file names: {len(train_filenames)}, Valid file names: {len(valid_filenames)}, Test file names: {len(test_filenames)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 400\n",
    "vocab_name = f'vg_large-bpe_{vocab_size}' # Also try 500, 750, 1000 vocab size\n",
    "vocab_state_dict_path = Path(f'../data/vocab/{vocab_name}.pkl')\n",
    "model_name = f'midi_transformer_knn-xl_{vocab_name}'\n",
    "model_load_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "model_save_path = Path(f'../data/checkpoints/{model_name}.dat')\n",
    "log_dir = Path(f'../tensorboard/{model_name}')\n",
    "tensorboard_writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MidiDataset says \"Look for the given filenames at the given score path. Load if they exist, if not create them'.\n",
    "\n",
    "We can use this to encode with the trained vocab if we pass it in as a param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset samples...\n"
     ]
    }
   ],
   "source": [
    "if not vocab_state_dict_path.exists():\n",
    "    # Basic vocab\n",
    "    dataset_vocab = MusicVocab()\n",
    "    \n",
    "    # Load (and / or create) dataset of unmerged samples\n",
    "    vocab_training_dataset = MidiDataset(vg_large_file_names, midi_path, score_path, sample_length, max_file_length)\n",
    "    print(f\"Loading dataset samples...\")\n",
    "    vocab_training_dataset.load_samples(dataset_vocab, \"cpu\")\n",
    "\n",
    "    # Train the vocab on the unmerged dataset, so it can learn the merges\n",
    "    print(f\"Training vocab...\")\n",
    "    trained_vocab = MusicVocab()\n",
    "    trained_vocab.train(vocab_training_dataset, max_vocab_size=vocab_size)\n",
    "    \n",
    "    print(f\"Saving vocab...\")\n",
    "    trained_vocab.save(vocab_state_dict_path)\n",
    "else:\n",
    "    print(f\"Loading vocab...\")\n",
    "    trained_vocab = MusicVocab.load(vocab_state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_score_path = Path(f'../data/numpy/{vocab_name}')\n",
    "\n",
    "# Use the trained vocab to load GPU datasets, which will create merged samples if we pass a new path\n",
    "train_dataset = MidiDataset(train_filenames, midi_path, merged_score_path, sample_length, max_file_length)\n",
    "valid_dataset = MidiDataset(valid_filenames, midi_path, merged_score_path, sample_length, max_file_length)\n",
    "test_dataset = MidiDataset(test_filenames, midi_path, merged_score_path, sample_length, max_file_length)\n",
    "\n",
    "print(f'Loading train samples')\n",
    "train_dataset.load_samples(trained_vocab, device)\n",
    "\n",
    "print(f'Loading valid samples')\n",
    "valid_dataset.load_samples(trained_vocab, device)\n",
    "\n",
    "print(f'Loading test samples')\n",
    "test_dataset.load_samples(trained_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train files: {len(train_dataset.file_lengths)}, Valid files: {len(valid_dataset.file_lengths)}, Test files: {len(test_dataset.file_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size can be changed for a second phase of training quite quickly, it only requires re-computing the indices, not re-loading the data.\n",
    "batch_size = 32\n",
    "train_sampler = ContiguousBatchSampler(train_dataset)\n",
    "valid_sampler = ContiguousBatchSampler(valid_dataset)\n",
    "test_sampler = ContiguousBatchSampler(test_dataset)\n",
    "\n",
    "print(f'Precomputing indices')\n",
    "train_sampler.precompute_indices(batch_size)\n",
    "valid_sampler.precompute_indices(batch_size)\n",
    "test_sampler.precompute_indices(batch_size)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_sampler=valid_sampler)\n",
    "test_data_loader = DataLoader(test_dataset, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderTransformer_KNN_XL(db_filepath=Path('../data/numpy/knn-demo'), vocab=trained_vocab, sample_length=sample_length, max_file_length=max_file_length, use_knn=True)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "eval_iters = 100\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(data_loader):\n",
    "    model.eval()\n",
    "        \n",
    "    xl_memories = None\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    \n",
    "    # Not working\n",
    "    # Start at a random point in the data, making sure we have enough data to evaluate\n",
    "    # offset = random.randint(0, len(data_loader.dataset) - (eval_iters + 1))\n",
    "    # data_iter = itertools.islice(iter(data_loader), offset, None)\n",
    "\n",
    "    data_iter = iter(data_loader)\n",
    "\n",
    "    for k in range(eval_iters):\n",
    "        file_idxs, batch = next(data_iter)\n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0] # drop absolute position from Y\n",
    "        _, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "        losses[k] = loss.item()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_log_losses = {  \n",
    "    \"train\" : [],\n",
    "    \"val\" : []\n",
    "}\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "def save_checkpoint(iterations):\n",
    "    train_loss = estimate_loss(train_data_loader)\n",
    "    val_loss = estimate_loss(valid_data_loader)\n",
    "    tensorboard_writer.add_scalar('Loss/train', train_loss, iterations)\n",
    "    tensorboard_writer.add_scalar('Loss/val', val_loss, iterations)\n",
    "    train_log_loss = train_loss.log10().item()\n",
    "    val_log_loss = val_loss.log10().item()\n",
    "    average_log_losses['train'].append(train_log_loss)\n",
    "    average_log_losses['val'].append(val_log_loss)\n",
    "    print(f'Epoch {epochs} / Iteration {iterations}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    torch.save({\n",
    "        'iter': iterations,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'vocab_state_dict': trained_vocab.state_dict(),\n",
    "        'losses': average_log_losses,\n",
    "        'epochs': epochs\n",
    "    }, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 200\n",
    "total_iterations = 100000\n",
    "start_iter = 0\n",
    "\n",
    "if model_load_path.exists():\n",
    "    checkpoint = torch.load(model_load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    average_log_losses = checkpoint['losses']\n",
    "    iterations = checkpoint['iter']\n",
    "    epochs = checkpoint['epochs']\n",
    "    start_iter = iterations + 1\n",
    "    print(f\"Loaded model from iteration {iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "remaining_iters = total_iterations - start_iter\n",
    "if remaining_iters != -1:\n",
    "\n",
    "    print(f\"Training from epoch {epochs} for {remaining_iters} iterations\")\n",
    "    \n",
    "    xl_memories = None\n",
    "    initial_file_idxs = None\n",
    "    train_data = iter(train_data_loader)\n",
    "    offset_iter = start_iter\n",
    "\n",
    "    for iteration in range(remaining_iters):\n",
    "        offset_iter = iteration + start_iter\n",
    "\n",
    "        if offset_iter % eval_interval == 0:\n",
    "            # Because we don't explicitly clear xl and knn mem here, there is always a risk that the eval loop leaves the file idx\n",
    "            # the same as the train loop, but with memories of the 'future' which aren't cleared. It could also break the epoch counter.\n",
    "            # The risk would be much smaller with a bigger data set, but with vg_large we loop through the data quite quickly.\n",
    "            save_checkpoint(offset_iter)\n",
    "\n",
    "        # Configure minibatch\n",
    "        file_idxs, batch = next(train_data)\n",
    "\n",
    "        if initial_file_idxs is None:\n",
    "            initial_file_idxs = file_idxs\n",
    "\n",
    "        if torch.equal(initial_file_idxs, file_idxs):\n",
    "            epochs += 1\n",
    "        \n",
    "        X, Y = batch[:, :-1], batch[:, 1:, 0]\n",
    "\n",
    "        # Forward pass\n",
    "        logits, loss, xl_memories = model(file_idxs, X, xl_memories, Y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    save_checkpoint(offset_iter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final training loss:', 10 ** average_log_losses['train'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final validation loss:', 10 ** average_log_losses['val'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['train'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_log_losses['val'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_idx = torch.zeros((1,1,2), dtype=torch.long, device=device)\n",
    "generated_tokens = model.generate(init_idx, max_new_tokens=512).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = generated_tokens[0, :, 0]\n",
    "trained_vocab.to_tokens(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream = idx_to_stream_enc(np.array(score), trained_vocab)\n",
    "generated_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_midi_file = random.choice(test_filenames)\n",
    "random_test_path = Path(midi_path, random_test_midi_file)\n",
    "random_test_idx_score = midifile_to_idx_score(random_test_path, trained_vocab)\n",
    "random_test_intro = random_test_idx_score[:sample_length]\n",
    "random_test_intro_stream = idx_to_stream_enc(np.array(random_test_intro[:, 0]), trained_vocab)\n",
    "random_test_intro_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_intro_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_init = torch.tensor(random_test_intro, device=device).unsqueeze(0)\n",
    "random_test_continued = model.generate(random_test_init, max_new_tokens=512).cpu()[0, :, 0]\n",
    "random_test_continued_stream = idx_to_stream_enc(np.array(random_test_continued), trained_vocab)\n",
    "random_test_continued_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_continued_stream.show('midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'5 - TransformerXL')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import chain\n",
    "from itertools import groupby\n",
    "from functools import reduce\n",
    "from typing import Collection, List\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from einops import rearrange, repeat, pack, unpack, einsum\n",
    "import faiss\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4090.\n"
     ]
    }
   ],
   "source": [
    "if device == \"cuda\":\n",
    "    print(f\"Device: {torch.cuda.get_device_name()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 18 17:27:54 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.31.01              Driver Version: 560.81         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   32C    P0             46W /  450W |    3513MiB /  24564MiB |     36%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        29      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        36      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        46      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = MusicVocab()\n",
    "vocab.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "\n",
    "Our memory-augmented transformer will be very similar to the vanilla model developed in the previous notebook.\n",
    "\n",
    "There will be three major additions, all of which are fairly simple:\n",
    "\n",
    "- Relative positional embeddings.\n",
    "- KNN lookup for keys (and their associated values).\n",
    "- Recurrent 'TransformerXL' style memory.\n",
    "\n",
    "## Einops\n",
    "\n",
    "First, lets condense our previous implementation in two ways\n",
    "\n",
    "- Add a dimension to our `MultiHeadAttention` module, abandoning the separate `SelfAttentionHead` module.\n",
    "- Switch to using einops for shape manipulation as it is both simpler to write and read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed, n_head = 8, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.n_head = n_head\n",
    "        self.head_size = n_embed // n_head\n",
    "        head_total_size = n_head * self.head_size\n",
    "        self.key = torch.nn.Linear(n_embed, head_total_size, bias=False)\n",
    "        self.query = torch.nn.Linear(n_embed, head_total_size, bias=False)\n",
    "        self.value = torch.nn.Linear(n_embed, head_total_size, bias=False)\n",
    "        self.proj = torch.nn.Linear(head_total_size, n_embed)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        # Split heads\n",
    "        q = rearrange(q, 'b t (h d) -> b h t d', h = self.n_head)\n",
    "        k = rearrange(k, 'b t (h d) -> b h t d', h = self.n_head)\n",
    "        v = rearrange(v, 'b t (h d) -> b h t d', h = self.n_head)\n",
    "\n",
    "        # Without einsum we had to swap dims using k.transpose(-2, -1)\n",
    "        w = einsum(q, k, 'b h i d, b h j d -> b h i j') * (self.head_size ** -0.5)\n",
    "        \n",
    "        # TODO: Relative positional encoding\n",
    "\n",
    "        i, j = w.shape[-2:]\n",
    "        mask = torch.tril(torch.ones((i,j), dtype = torch.bool))\n",
    "        w = w.masked_fill(mask, float('-inf'))\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        attention_scores = w@v\n",
    "\n",
    "        # Concat heads\n",
    "        attention_scores = rearrange(attention_scores, 'b h t d -> b t (h d)')\n",
    "\n",
    "        # TODO: KNN memory\n",
    "\n",
    "        out = self.proj(attention_scores)\n",
    "        return self.dropout(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Memory\n",
    "\n",
    "If we want to add KNN memory, we need an indexed data store to look up and retrieve keys and values.\n",
    "\n",
    "For the index we can use [Faiss](https://github.com/facebookresearch/faiss) from Meta.\n",
    "\n",
    "For the data store we can simply use a memory-mapped numpy array.\n",
    "\n",
    "The following code is taked from the [Colab Notebook](https://colab.research.google.com/drive/1XZz1sjNt1MKRG6ul_hOGSJFQLS4lRtmJ?usp=sharing#scrollTo=mxnmadjyLgH1) accompanying the [Coding a Paper](https://www.youtube.com/playlist?list=PLam9sigHPGwOe8VDoS_6VT4jjlgs9Uepb) series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, dim, max_memories, db_filepath):\n",
    "        self.dim = dim\n",
    "        self.max_memories = max_memories\n",
    "        self.shape = (max_memories, 2, dim) # TODO: Memory per batch dim, cleared when file is exhausted\n",
    "        self.db_offset = 0\n",
    "        self.db_filepath = db_filepath\n",
    "        self.db = np.memmap(self.db_filepath, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
    "        self.index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "\n",
    "    def add_to_db(self, new_data):\n",
    "        new_data_len = new_data.shape[0] # (b t)\n",
    "        ids = (np.arange(new_data_len) + self.db_offset)\n",
    "        self.db[ids] = new_data.detach().numpy()\n",
    "        self.db_offset += new_data_len\n",
    "        # Write to file\n",
    "        self.db.flush()\n",
    "\n",
    "\n",
    "    def search_and_retrieve(self, query, k):\n",
    "\n",
    "        # The tooltip says the args are (n, x, k) but that's the CPP api, it's actually (x, k) in Python (n is the first dim of x anyway so can be inferred).\n",
    "        distances, indices = self.index.search(query, k)\n",
    "        \n",
    "        kvs = self.db[indices]\n",
    "        return kvs\n",
    "\n",
    "    def add(self, new_data):\n",
    "        new_data = new_data = rearrange(new_data, 'b t 2 (h d) -> (b t) 2 (h d)')\n",
    "\n",
    "        # Add to db\n",
    "        self.add_to_db(new_data)\n",
    "\n",
    "        # Only keys are used in knn index\n",
    "        keys, vals = new_data.unbind(dim=-2)\n",
    "\n",
    "        # Add (b t) (h d) tensors to index\n",
    "        keys = keys.detach().numpy()\n",
    "        keys = np.ascontiguousarray(keys)\n",
    "        self.index.add(keys)\n",
    "\n",
    "    def search(self, query, k):\n",
    "        T = query.shape[1]\n",
    "        query = rearrange(query, 'b t (h d) -> (b t) (h d)')\n",
    "\n",
    "        kvs = self.search_and_retrieve(np.ascontiguousarray(query.detach().numpy()), k)\n",
    "        kvs = torch.tensor(kvs)\n",
    "        kvs = kvs = rearrange(kvs, '(b t) k 2 (h d) -> b t k 2 (h d)', t = T)\n",
    "        \n",
    "        return kvs\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.index.reset()\n",
    "        self.db[:] = 0\n",
    "        self.db_offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Test KNN\n",
    "- Add KNN lookup to vanilla transformer\n",
    "- XL recurrence\n",
    "- Relative Positional embeddings\n",
    "\n",
    "Once all that is working, consider\n",
    "\n",
    "- Ragged memmap for data loading (allows moving to bigger dataset)\n",
    "- Byte pair encoding (bigger vocab with common token pairs gives us a bigger effective context) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'6 - Byte Pair encoding')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import chain, cycle, groupby\n",
    "from functools import reduce\n",
    "from typing import Collection, List\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from einops import rearrange, repeat, pack, unpack, einsum\n",
    "import faiss\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding (BPE)\n",
    "\n",
    "## What is the aim here?\n",
    "\n",
    "- Increase information density in the context by introducing dedicated tokens for common pairs of tokens (and pairs of pairs, and pairs of those, etc etc)\n",
    "\n",
    "This will be achieved by adapting the `Vocab` class to be *trainable*.\n",
    "\n",
    "Training the `Vocab` class means feeding it a bunch of example data (which may or may not be the training set - rare items may be deliberately represented).\n",
    "\n",
    "It uses this example data to *extend* the base vocabulary with pairs of tokens, and then pairs of those pairs etc etc. until the desired vocab size is reached.\n",
    "\n",
    "This trained extended vocab can then be used to encode training data in a much more efficient, compressed form.\n",
    "\n",
    "In our particular music-based case, you might imagine common chords being represented as a single token rather than a whole string of notes and durations.\n",
    "\n",
    "> A C Major with notes that lasted slightly different lengths of time wouldn't be grouped unfortunately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  0],\n",
      "        [ 2,  0],\n",
      "        [ 3,  0],\n",
      "        [ 4,  0],\n",
      "        [ 5,  0],\n",
      "        [ 6,  0],\n",
      "        [ 7,  0],\n",
      "        [ 8,  0],\n",
      "        [ 9,  0],\n",
      "        [10,  0],\n",
      "        [11,  0],\n",
      "        [12,  0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    }
   ],
   "source": [
    "# Create a nested tensor\n",
    "# Zeros represent the time idx\n",
    "nested_tensor = torch.nested.nested_tensor([torch.tensor([[[1,0], [2,0]], [[3,0], [4,0]]]), torch.tensor([[[5,0], [6,0]]]), torch.tensor([[[7,0], [8,0]], [[9,0], [10,0]], [[11,0], [12,0]]])])\n",
    "\n",
    "# Manually flatten the nested tensor by concatenating the individual tensors\n",
    "flattened_tensor = torch.cat([t.flatten(0,1) for t in nested_tensor.unbind()])\n",
    "\n",
    "print(flattened_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "print(flattened_tensor[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicVocab():\n",
    "    def __init__(self, cache_path):\n",
    "        self.itos = {k:v for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.stoi = {v:k for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.cache_path = cache_path\n",
    "    \n",
    "    def to_indices(self, tokens):\n",
    "        return [self.stoi[w] for w in tokens]\n",
    "\n",
    "    def to_tokens(self, idxs, sep=' '):\n",
    "        items = [self.itos[idx] for idx in idxs]\n",
    "        return sep.join(items) if sep is not None else items\n",
    "    \n",
    "    def get_stats(self, idxs):\n",
    "        stats = {}\n",
    "        for pair in zip(idxs[:-1], idxs[1:]):\n",
    "            stats[pair] = stats.get(pair, 0) + 1\n",
    "        return stats\n",
    "\n",
    "    def merge(self, idxs, pair, idx):\n",
    "        new_idxs = []\n",
    "        i = 0\n",
    "        while i < len(idxs):\n",
    "            current_item = idxs[i]\n",
    "            next_item = idxs[i+1] if i < len(idxs) - 1 else None\n",
    "            if next_item is not None and current_item == pair[0] and next_item == pair[1]:\n",
    "                new_idxs.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_idxs.append(current_item)\n",
    "                i += 1\n",
    "        return new_idxs\n",
    "\n",
    "    # Pass in data already encoded using untrained vocab\n",
    "    def train(self, dataset, max_vocab_size=400):\n",
    "        # Might have to skip the clone, depending on memory usage\n",
    "        idxs = torch.cat([t.flatten(0,1) for t in dataset.data.unbind()]) # Flatten the nested tensor\n",
    "        idxs = idxs[:, 0].detach().cpu().tolist() # Discard time idx and convert to numpy\n",
    "        num_merges = max_vocab_size - self.size\n",
    "        merges = {}\n",
    "\n",
    "        for i in range(num_merges):\n",
    "            stats = self.get_stats(idxs)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = self.size + i\n",
    "            print(f\"Merging {pair} to a new token {idx}\")\n",
    "            idxs = self.merge(idxs, pair, idx)\n",
    "            merges[pair] = idx\n",
    "        \n",
    "        for (p0, p1), idx in merges.items():\n",
    "            value = self.itos[p0] + self.itos[p1]\n",
    "            self.itos[idx] = value\n",
    "            self.stoi[value] = idx\n",
    "\n",
    "        self.trained = True\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(self.itos, file)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as file:\n",
    "            self.itos = pickle.load(file)\n",
    "    \n",
    "    def encode(self, note_position_score):\n",
    "        return None\n",
    "    \n",
    "    def decode(self, note_index_score):\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self): return self.stoi[SOS]\n",
    "    @property\n",
    "    def eos_idx(self): return self.stoi[EOS]\n",
    "    @property\n",
    "    def sep_idx(self): return self.stoi[SEP]\n",
    "    @property\n",
    "    def pad_idx(self): return self.stoi[PAD]\n",
    "    @property\n",
    "    def note_position_enc_range(self): return (self.stoi[SEP], self.stoi[DURATION_END]+1)\n",
    "    @property\n",
    "    def note_range(self): return self.stoi[NOTE_START], self.stoi[NOTE_END]+1\n",
    "    @property\n",
    "    def duration_range(self): return self.stoi[DURATION_START], self.stoi[DURATION_END]+1\n",
    "    @property\n",
    "    def size(self): return len(self.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "- Should we consider SEPARATOR_IDX as a hard terminator of bpe (like a word space) and pre-chunk into simultaneous 'actions'? Instead of 'optional space followed by a sequence of chars' it would be 'optional separator followed by an action (sequence of notes and durations)'.\n",
    "\n",
    "Answer: \n",
    "- No need because an 'action' is *always* followed by a separator, it's not like we have a range of punctuation to differentiate (i.e. dog. vs dog, vs dog!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# Create a nested tensor\n",
    "nested_tensor = torch.nested.nested_tensor([torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5, 6]]), torch.tensor([[7, 8], [9, 10], [11, 12]])])\n",
    "\n",
    "# Manually flatten the nested tensor by concatenating the individual tensors\n",
    "flattened_tensor = torch.cat([t.flatten() for t in nested_tensor.unbind()])\n",
    "\n",
    "print(flattened_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '6 - Byte Pair encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m6 - Byte Pair encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '6 - Byte Pair encoding'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'6 - Byte Pair encoding')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import chain, cycle, groupby\n",
    "from functools import reduce\n",
    "from typing import Collection, List\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from data_loading import *\n",
    "from einops import rearrange, repeat, pack, unpack, einsum\n",
    "import faiss\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding (BPE)\n",
    "\n",
    "## What is the aim here?\n",
    "\n",
    "- Increase information density in the context by introducing dedicated tokens for common pairs of tokens (and pairs of pairs, and pairs of those, etc etc)\n",
    "\n",
    "This will be achieved by adapting the `Vocab` class to be *trainable*.\n",
    "\n",
    "Training the `Vocab` class means feeding it a bunch of example data (which may or may not be the training set - rare items may be deliberately represented).\n",
    "\n",
    "It uses this example data to *extend* the base vocabulary with pairs of tokens, and then pairs of those pairs etc etc. until the desired vocab size is reached.\n",
    "\n",
    "This trained extended vocab can then be used to encode training data in a much more efficient, compressed form.\n",
    "\n",
    "In our particular music-based case, you might imagine common chords being represented as a single token rather than a whole string of notes and durations.\n",
    "\n",
    "> A C Major with notes that lasted slightly different lengths of time wouldn't be grouped unfortunately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nested_tensor([\n",
       "  tensor([[[1, 0],\n",
       "           [2, 0]],\n",
       "  \n",
       "          [[3, 0],\n",
       "           [4, 0]]]),\n",
       "  tensor([[[5, 0],\n",
       "           [6, 0]]]),\n",
       "  tensor([[[ 7,  0],\n",
       "           [ 8,  0]],\n",
       "  \n",
       "          [[ 9,  0],\n",
       "           [10,  0]],\n",
       "  \n",
       "          [[11,  0],\n",
       "           [12,  0]]])\n",
       "])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a nested tensor\n",
    "# Zeros represent the time idx\n",
    "nested_tensor = torch.nested.nested_tensor([torch.tensor([[[1,0], [2,0]], [[3,0], [4,0]]]), torch.tensor([[[5,0], [6,0]]]), torch.tensor([[[7,0], [8,0]], [[9,0], [10,0]], [[11,0], [12,0]]])])\n",
    "nested_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0],\n",
       "        [ 2,  0],\n",
       "        [ 3,  0],\n",
       "        [ 4,  0],\n",
       "        [ 5,  0],\n",
       "        [ 6,  0],\n",
       "        [ 7,  0],\n",
       "        [ 8,  0],\n",
       "        [ 9,  0],\n",
       "        [10,  0],\n",
       "        [11,  0],\n",
       "        [12,  0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_tensor = torch.cat([t.flatten(0,1) for t in nested_tensor.unbind()])\n",
    "flattened_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicVocab():\n",
    "    def __init__(self):\n",
    "        self.itos = {k:v for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.stoi = {v:k for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.idx_to_elem = {k:k for k,v in enumerate(ALL_TOKENS)} # 1 is 1, 2 is 2 etc. until we merge.\n",
    "        self.merges = None\n",
    "    \n",
    "    def to_indices(self, tokens):\n",
    "        return [self.stoi[w] for w in tokens]\n",
    "\n",
    "    def to_tokens(self, idxs, sep=' '):\n",
    "        items = [self.itos[idx] for idx in idxs]\n",
    "        return sep.join(items) if sep is not None else items\n",
    "    \n",
    "    def to_element(self, idxs):\n",
    "        return [self.idx_to_elem[idx] for idx in idxs]\n",
    "\n",
    "    def get_stats(self, idxs):\n",
    "        stats = {}\n",
    "        for pair in zip(idxs[:-1], idxs[1:]):\n",
    "            stats[pair] = stats.get(pair, 0) + 1\n",
    "        return stats\n",
    "\n",
    "    def merge(self, idxs, pair, idx):\n",
    "        new_idxs = []\n",
    "        i = 0\n",
    "        while i < len(idxs):\n",
    "            current_item = idxs[i]\n",
    "            next_item = idxs[i+1] if i < len(idxs) - 1 else None\n",
    "            if next_item is not None and current_item == pair[0] and next_item == pair[1]:\n",
    "                new_idxs.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_idxs.append(current_item)\n",
    "                i += 1\n",
    "        return new_idxs\n",
    "    \n",
    "    def concat_lists(self, list1, list2):\n",
    "        if not isinstance(list1, list):\n",
    "            list1 = [list1]\n",
    "        if not isinstance(list2, list):\n",
    "            list2 = [list2]\n",
    "        return list1 + list2\n",
    "\n",
    "    # Pass in data already encoded using untrained vocab\n",
    "    def train(self, dataset, max_vocab_size):\n",
    "\n",
    "        if self.merges is not None:\n",
    "            raise Exception(\"Already trained\")\n",
    "        \n",
    "        self.merges = {}\n",
    "\n",
    "        # Might have to skip the clone, depending on memory usage\n",
    "        idxs = torch.cat([t.flatten(0,1) for t in dataset.data.unbind()]) # Flatten the nested tensor\n",
    "        idxs = idxs[:, 0].detach().cpu().tolist() # Discard time idx and convert to numpy\n",
    "        initial_size = self.size\n",
    "        num_merges = max_vocab_size - initial_size\n",
    "\n",
    "        for i in range(num_merges):\n",
    "            stats = self.get_stats(idxs)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = initial_size + i\n",
    "            print(f\"Merging {pair} to a new token {idx}\") \n",
    "            idxs = self.merge(idxs, pair, idx)\n",
    "            self.merges[pair] = idx\n",
    "        \n",
    "        for (p0, p1), idx in self.merges.items():\n",
    "            value = f\"{self.itos[p0]}{self.itos[p1]}\"\n",
    "            self.itos[idx] = value\n",
    "            self.stoi[value] = idx\n",
    "            self.idx_to_elem[idx] = self.concat_lists(self.idx_to_elem[p0] ,self.idx_to_elem[p1])\n",
    "    \n",
    "    def save(self, path):\n",
    "        state = {\n",
    "            'itos': self.itos,\n",
    "            'stoi': self.stoi,\n",
    "            'idx_to_elem': self.idx_to_elem,\n",
    "            'merges': self.merges\n",
    "        }\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(state, file)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as file:\n",
    "            state = pickle.load(file)\n",
    "            self.itos = state['itos']\n",
    "            self.stoi = state['stoi']\n",
    "            self.idx_to_elem = state['idx_to_elem']\n",
    "            self.merges = state['merges']\n",
    "    \n",
    "    def encode(self, note_position_score):\n",
    "        nps = note_position_score.copy()\n",
    "        note_idx_score = nps[:, :2] # Note and duration, drop tidx\n",
    "        pos_score = nps[:, 2]\n",
    "        note_min_idx, _ = self.note_range\n",
    "        dur_min_idx, _ = self.duration_range\n",
    "        note_idx_score += np.array([note_min_idx, dur_min_idx])\n",
    "        note_idx_score = note_idx_score.reshape(-1)\n",
    "        \n",
    "        while True:\n",
    "            stats = self.get_stats(note_idx_score)\n",
    "            # Iterate keys and get the pair with the min number of merges, so we do earlier merges first\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float('inf')))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "            idx = self.merges[pair]\n",
    "            note_idx_score = self.merge(note_idx_score, pair, idx)\n",
    "\n",
    "        # Questions:\n",
    "        # 1. How do we handle the position score? - Pass the position to merge and it can be included in the merged score\n",
    "        # 2. How do we decode to midi? We would need to 'un-pair' the tokens\n",
    "\n",
    "        return note_idx_score\n",
    "    \n",
    "    def decode(self, note_idx_score):\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self): return self.stoi[SOS]\n",
    "    @property\n",
    "    def eos_idx(self): return self.stoi[EOS]\n",
    "    @property\n",
    "    def sep_idx(self): return self.stoi[SEP]\n",
    "    @property\n",
    "    def pad_idx(self): return self.stoi[PAD]\n",
    "    @property\n",
    "    def note_position_enc_range(self): return (self.stoi[SEP], self.stoi[DURATION_END]+1)\n",
    "    @property\n",
    "    def note_range(self): return self.stoi[NOTE_START], self.stoi[NOTE_END]+1\n",
    "    @property\n",
    "    def duration_range(self): return self.stoi[DURATION_START], self.stoi[DURATION_END]+1\n",
    "    @property\n",
    "    def size(self): return len(self.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "- Should we consider SEPARATOR_IDX as a hard terminator of bpe (like a word space) and pre-chunk into simultaneous 'actions'? Instead of 'optional space followed by a sequence of chars' it would be 'optional separator followed by an action (sequence of notes and durations)'.\n",
    "\n",
    "Answer: \n",
    "- No need because an 'action' is *always* followed by a separator, it's not like we have a range of punctuation to differentiate (i.e. dog. vs dog, vs dog!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = MusicVocab()\n",
    "init_vocab_size = vocab.size\n",
    "init_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 256\n",
    "max_file_length = 32\n",
    "vg_large_path = Path('../data/midi/vg_large')\n",
    "vg_large_file_names = [f for f in os.listdir(vg_large_path) if os.path.isfile(os.path.join(vg_large_path, f))]\n",
    "midi_path = Path('../data/midi/vg_large')\n",
    "score_path = Path(f'../data/numpy/vg_large/all')\n",
    "\n",
    "dataset = MidiDataset(vg_large_file_names, midi_path, score_path, sample_length, max_file_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load_samples(vocab, device) # Could load directly to CPU here as it is only used for training the vocab but wanted to replicate existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging (3, 136) to a new token 389\n",
      "Merging (136, 389) to a new token 390\n",
      "Merging (2, 2) to a new token 391\n",
      "Merging (3, 134) to a new token 392\n",
      "Merging (134, 392) to a new token 393\n",
      "Merging (134, 389) to a new token 394\n"
     ]
    }
   ],
   "source": [
    "vocab.train(dataset, max_vocab_size=395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_vocab_size = vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389: <|sep|>d4\n",
      "390: d4<|sep|>d4\n",
      "391: <|pad|><|pad|>\n",
      "392: <|sep|>d2\n",
      "393: d2<|sep|>d2\n",
      "394: d2<|sep|>d4\n"
     ]
    }
   ],
   "source": [
    "for idx in range(init_vocab_size, trained_vocab_size):\n",
    "    print(f\"{idx}: {vocab.itos[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389: [3, 136]\n",
      "390: [136, 3, 136]\n",
      "391: [2, 2]\n",
      "392: [3, 134]\n",
      "393: [134, 3, 134]\n",
      "394: [134, 3, 136]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(init_vocab_size, trained_vocab_size):\n",
    "    print(f\"{idx}: {vocab.idx_to_elem[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

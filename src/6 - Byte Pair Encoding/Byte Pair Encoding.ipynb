{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'6 - Byte Pair encoding')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import chain, cycle, groupby\n",
    "from functools import reduce\n",
    "from typing import Collection, List\n",
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "musescore_path = '/usr/bin/mscore'\n",
    "m21.environment.set('musicxmlPath', musescore_path)\n",
    "m21.environment.set('musescoreDirectPNGPath', musescore_path)\n",
    "from midi_encoding import *\n",
    "from data_loading import *\n",
    "from einops import rearrange, repeat, pack, unpack, einsum\n",
    "import faiss\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding (BPE)\n",
    "\n",
    "## What is the aim here?\n",
    "\n",
    "- Increase information density in the context by introducing dedicated tokens for common pairs of tokens (and pairs of pairs, and pairs of those, etc etc)\n",
    "\n",
    "This will be achieved by adapting the `Vocab` class to be *trainable*.\n",
    "\n",
    "Training the `Vocab` class means feeding it a bunch of example data (which may or may not be the training set - rare items may be deliberately represented).\n",
    "\n",
    "It uses this example data to *extend* the base vocabulary with pairs of tokens, and then pairs of those pairs etc etc. until the desired vocab size is reached.\n",
    "\n",
    "This trained extended vocab can then be used to encode training data in a much more efficient, compressed form.\n",
    "\n",
    "In our particular music-based case, you might imagine common chords being represented as a single token rather than a whole string of notes and durations.\n",
    "\n",
    "> A C Major with notes that lasted slightly different lengths of time wouldn't be grouped unfortunately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nested tensor\n",
    "# Zeros represent the time idx\n",
    "nested_tensor = torch.nested.nested_tensor([torch.tensor([[[1,0], [2,0]], [[3,0], [4,0]]]), torch.tensor([[[5,0], [6,0]]]), torch.tensor([[[7,0], [8,0]], [[9,0], [10,0]], [[11,0], [12,0]]])])\n",
    "nested_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_tensor = torch.cat([t.flatten(0,1) for t in nested_tensor.unbind()])\n",
    "flattened_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicVocab():\n",
    "    def __init__(self):\n",
    "        self.itos = {k:v for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.stoi = {v:k for k,v in enumerate(ALL_TOKENS)}\n",
    "        self.idx_to_elem = {k:[k] for k,v in enumerate(ALL_TOKENS)} # 1 is [1], 2 is [2] etc. until we merge.\n",
    "        self.merges = None\n",
    "    \n",
    "    def to_indices(self, tokens):\n",
    "        return [self.stoi[w] for w in tokens]\n",
    "\n",
    "    def to_tokens(self, idxs, sep=' '):\n",
    "        items = [self.itos[idx] for idx in idxs]\n",
    "        return sep.join(items) if sep is not None else items\n",
    "    \n",
    "    def to_element(self, idxs):\n",
    "        return [self.idx_to_elem[idx] for idx in idxs]\n",
    "\n",
    "    def get_stats(self, idxs):\n",
    "        stats = {}\n",
    "        for pair in zip(idxs[:-1], idxs[1:]):\n",
    "            stats[pair] = stats.get(pair, 0) + 1\n",
    "        return stats\n",
    "\n",
    "    def merge(self, idxs, pos, pair, idx):\n",
    "        new_idxs = []\n",
    "        new_pos = None if pos is None else []\n",
    "        i = 0\n",
    "        while i < len(idxs):\n",
    "            # Need to make sure we don't merge across time steps, otherwise we can't assign a tidx to the merged token\n",
    "            current_item = idxs[i]\n",
    "\n",
    "            if pos is not None:\n",
    "                current_pos = pos[i]\n",
    "                new_pos.append(current_pos)\n",
    "\n",
    "            next_item = idxs[i+1] if i < len(idxs) - 1 else None\n",
    "\n",
    "            if next_item is not None and current_item == pair[0] and next_item == pair[1]:\n",
    "                new_idxs.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_idxs.append(current_item)\n",
    "                i += 1\n",
    "\n",
    "        return new_idxs, new_pos\n",
    "\n",
    "    # Pass in data already encoded using untrained vocab\n",
    "    def train(self, dataset, max_vocab_size):\n",
    "\n",
    "        if self.merges is not None:\n",
    "            raise Exception(\"Already trained\")\n",
    "        \n",
    "        self.merges = {}\n",
    "\n",
    "        # Might have to skip the clone, depending on memory usage\n",
    "        idxs = torch.cat([t.flatten(0,1) for t in dataset.data.unbind()]) # Flatten the nested tensor\n",
    "        idxs = idxs[:, 0].detach().cpu().tolist() # Discard time idx and convert to list\n",
    "        initial_size = self.size\n",
    "        num_merges = max_vocab_size - initial_size\n",
    "\n",
    "        for i in range(num_merges):\n",
    "            stats = self.get_stats(idxs)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = initial_size + i\n",
    "            print(f\"Merging {pair} to a new token {idx}\")\n",
    "            idxs, _ = self.merge(idxs, None, pair, idx)\n",
    "            self.merges[pair] = idx\n",
    "        \n",
    "        for (p0, p1), idx in self.merges.items():\n",
    "            value = f\"{self.itos[p0]} {self.itos[p1]}\"\n",
    "            self.itos[idx] = value\n",
    "            self.stoi[value] = idx\n",
    "            self.idx_to_elem[idx] = self.idx_to_elem[p0] + self.idx_to_elem[p1]\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'idx_to_elem': self.idx_to_elem,\n",
    "            'merges': self.merges\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.merges = state_dict['merges']\n",
    "        self.idx_to_elem = state_dict['idx_to_elem']\n",
    "        self.itos = {k:self.to_tokens(v) for k,v in enumerate(self.idx_to_elem.values())}\n",
    "        self.stoi = {v:k for k,v in enumerate(self.itos.values())}\n",
    "    \n",
    "    def encode(self, note_position_score):\n",
    "        nps = note_position_score.copy()\n",
    "        note_dur_score = nps[:, :2] # Note and duration, drop tidx\n",
    "        \n",
    "        # Offset the note and duration values by the min index to get their index\n",
    "        note_min_idx, _ = self.note_range\n",
    "        dur_min_idx, _ = self.duration_range\n",
    "        note_idx_score = note_dur_score + np.array([note_min_idx, dur_min_idx])\n",
    "\n",
    "        note_idx_score = note_idx_score.reshape(-1) # Flatten note and duration into a single dimension\n",
    "        pos_score = np.repeat(nps[:, 2], 2) # Double up positions for flattened note and duration\n",
    "        \n",
    "        while True:\n",
    "            stats = self.get_stats(note_idx_score)\n",
    "\n",
    "            # Iterate keys and get the pair with the min number of merges, so we do earlier merges first\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float('inf')))\n",
    "            \n",
    "            if pair not in self.merges:\n",
    "                print(\"No more merges to do\")\n",
    "                break\n",
    "            else:\n",
    "                idx = self.merges[pair]\n",
    "                print(f\"Replacing {pair} with token {idx}\")\n",
    "                note_idx_score, pos_score = self.merge(note_idx_score, pos_score, pair, idx)\n",
    "\n",
    "        return np.array(note_idx_score), np.array(pos_score)\n",
    "    \n",
    "    def decode(self, note_idx_score):\n",
    "        # Convert idxs to positions and pair up note / durations\n",
    "        merge_chunks = [self.idx_to_elem[idx] for idx in note_idx_score]\n",
    "        position_score = np.array(list(chain(*merge_chunks))).reshape(-1, 2)\n",
    "\n",
    "        # Offset the note and duration idxs by their respective min index to get their actual value\n",
    "        if position_score.shape[0] != 0: \n",
    "            note_min_idx, _ = self.note_range\n",
    "            dur_min_idx, _ = self.duration_range\n",
    "            position_score -= np.array([note_min_idx, dur_min_idx])\n",
    "\n",
    "        return position_score\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self): return self.stoi[SOS]\n",
    "    @property\n",
    "    def eos_idx(self): return self.stoi[EOS]\n",
    "    @property\n",
    "    def sep_idx(self): return self.stoi[SEP]\n",
    "    @property\n",
    "    def pad_idx(self): return self.stoi[PAD]\n",
    "    @property\n",
    "    def note_position_enc_range(self): return (self.stoi[SEP], self.size)\n",
    "    @property\n",
    "    def note_range(self): return self.stoi[NOTE_START], self.stoi[NOTE_END]+1\n",
    "    @property\n",
    "    def duration_range(self): return self.stoi[DURATION_START], self.stoi[DURATION_END]+1\n",
    "    @property\n",
    "    def size(self): return len(self.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "- Should we consider SEPARATOR_IDX as a hard terminator of bpe (like a word space) and pre-chunk into simultaneous 'actions'? Instead of 'optional space followed by a sequence of chars' it would be 'optional separator followed by an action (sequence of notes and durations)'.\n",
    "\n",
    "Answer: \n",
    "- No need because an 'action' is *always* followed by a separator, it's not like we have a range of punctuation to differentiate (i.e. dog. vs dog, vs dog!).\n",
    "- However we did need to prevent merging across time index boundaties to ensure each token had a distinct timestep, which meant skipping a merge during encoding if the previous pair was SEP, DUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vocab = MusicVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 256\n",
    "max_file_length = 32\n",
    "vg_large_path = Path('../data/midi/vg_large')\n",
    "vg_large_file_names = [f for f in os.listdir(vg_large_path) if os.path.isfile(os.path.join(vg_large_path, f))]\n",
    "midi_path = Path('../data/midi/vg_large')\n",
    "score_path = Path(f'../data/numpy/vg_large/all')\n",
    "\n",
    "dataset = MidiDataset(vg_large_file_names, midi_path, score_path, sample_length, max_file_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load_samples(dataset_vocab, device) # Could load directly to CPU here as it is only used for training the vocab but wanted to replicate existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = MusicVocab()\n",
    "init_vocab_size = vocab.size\n",
    "init_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.train(dataset, max_vocab_size=395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_vocab_size = vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(init_vocab_size, init_vocab_size + 6):\n",
    "    print(f\"{idx}: {vocab.itos[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(init_vocab_size, init_vocab_size + 6):\n",
    "    print(f\"{idx}: {vocab.idx_to_elem[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fantasy_midi_path = Path('../data/midi/Mana_GB_Final Fantasy Adventure_Battle 2.mid')\n",
    "final_fantasy_midi = m21.midi.MidiFile()\n",
    "final_fantasy_midi.open(final_fantasy_midi_path)\n",
    "final_fantasy_midi.read()\n",
    "final_fantasy_midi.close()\n",
    "\n",
    "final_fantasy_m21stream = m21.midi.translate.midiFileToStream(final_fantasy_midi)\n",
    "final_fantasy_m21stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fantasy_idx_score = midifile_to_idx_score(final_fantasy_midi_path, vocab)\n",
    "\n",
    "vocab.to_tokens(final_fantasy_idx_score[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fantasy_idx_score.shape # 3162 before adding 6 tokens to the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_final_fantasy_stream = idx_to_stream_enc(final_fantasy_idx_score[:, 0], vocab)\n",
    "reconstructed_final_fantasy_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fantasy_m21stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_final_fantasy_stream.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!\n",
    "\n",
    "## Save / Restore\n",
    "\n",
    "It is important that we use the same vocab to decode data that we used to encode it, otherwise tokens might not exist or have other meanings.\n",
    "\n",
    "This also goes for decoding performances generated by the model. We must use the same vocab which encoded the training data (and all training data must have been encoded with the same vocab). This stands to reason, otherwise tokens will have no consistent meaning.\n",
    "\n",
    "For this reason we should save it alongside our model during training so that we can load it during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_state = vocab.state_dict()\n",
    "\n",
    "untrained_vocab = MusicVocab()\n",
    "untrained_vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_vocab.load_state_dict(trained_state)\n",
    "untrained_vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_final_fantasy_stream = idx_to_stream_enc(final_fantasy_idx_score[:, 0], untrained_vocab)\n",
    "untrained_final_fantasy_stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_final_fantasy_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in untrained_vocab.itos.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in untrained_vocab.stoi.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and restore looking good.\n",
    "\n",
    "## Adding to the training loop\n",
    "\n",
    "I think the method will be\n",
    "\n",
    "1. Create a vocab\n",
    "2. Restore vocab and load merged data if exists\n",
    "3. If doesn't exist\n",
    "- Load unmerged data.\n",
    "- Train vocab and save.\n",
    "- Merge data and save.\n",
    "\n",
    "A dataset is **useless** without the vocab that encoded it, as is a model without the vocab of the data it was trained on, so save it in the model checkpoints, and load when restoring a model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
